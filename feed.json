{
    "version": "https://jsonfeed.org/version/1",
    "title": "dunghv.github.io",
    "description": "",
    "home_page_url": "https://dunghvcs.github.io",
    "feed_url": "https://dunghvcs.github.io/feed.json",
    "user_comment": "",
    "icon": "https://dunghvcs.github.io/media/website/CVISLab-removebg-preview.png",
    "author": {
        "name": "Van-Dung Hoang"
    },
    "items": [
        {
            "id": "https://dunghvcs.github.io/winter-workshop-2017.html",
            "url": "https://dunghvcs.github.io/winter-workshop-2017.html",
            "title": "Winter Workshop 2017",
            "summary": "Thị giác máy tính trong các hệ thống thông minh (Computer vision for intelligent systems) Topics: Computer vision Advanced driver assistance systems Autonomous vehicle Intelligent transport systems Intelligent security systems Advance intelligent systems Thị giác máy tính (Computer vision) là lĩnh vực đã và đang phát triển mạnh mẽ trên&hellip;",
            "content_html": "<p class=\"zfr3Q CDt4Ke \" dir=\"ltr\"><span style=\"color: #169179;\"><strong><span class=\"C9DxTc \">Thị giác máy tính trong các hệ thống thông minh (Computer vision for intelligent systems)</span></strong></span></p>\n<p dir=\"ltr\">Topics:<br>Computer vision<br>Advanced driver assistance systems<br>Autonomous vehicle <br>Intelligent transport systems<br>Intelligent security systems<br>Advance intelligent systems</p>\n<p class=\"zfr3Q CDt4Ke \" dir=\"ltr\"><span class=\"C9DxTc \">Thị giác máy tính (Computer vision) là lĩnh vực đã và đang phát triển mạnh mẽ trên thế giới hiện nay. Thị giác máy tính bao gồm các phương pháp thu nhận, xử lý ảnh kỹ thuật số, phân tích và trích xuất đặc trưng và kết hợp với trí tuệ nhân tạo để tạo ra các hệ thống thông minh. Một số hệ thống thông minh sử dụng thị giác máy tính như:</span></p>\n<p class=\"zfr3Q CDt4Ke \" dir=\"ltr\"><span class=\"C9DxTc \">Hệ thống xe không người lái: Hiện nay, rất nhiều tập đoàn công nghiệp và công nghệ đang đầu tư cho việc phát triển các loại xe không người lái, với mục tiêu tiến tới là các phương tiện giao thông đều có thể tự động điều hướng mà không cần phải có người lái. Có nhiều loại thiết bị, cảm biến và công nghệ thiết yếu được sử dụng để tạo nên xe không người lái: camera, radar kiểm soát hành trình, cảm biến ước lượng chuyển động, thiết bị kiểm soát ổn định điện tử, bản đồ điện tử và GPS kết nối vệ tinh,… Trong đó vai trò của lĩnh vực thị giác máy tính là hết sức quan trọng trong việc thu thập hình ảnh đến phân tích hình ảnh, trích xuất đặc trưng đến việc phát hiện, nhận các đối tượng tham gia giao thông và hiểu biết môi trường xung quanh để ra quyết định điều hướng xe phù hợp, đảm bảo an toàn và lộ trình đường đi.</span></p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://dunghvcs.github.io/media/posts/20/WS2017.png\" alt=\"\" width=\"660\" height=\"653\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://dunghvcs.github.io/media/posts/20/responsive/WS2017-xs.png 640w ,https://dunghvcs.github.io/media/posts/20/responsive/WS2017-sm.png 768w ,https://dunghvcs.github.io/media/posts/20/responsive/WS2017-md.png 1024w ,https://dunghvcs.github.io/media/posts/20/responsive/WS2017-lg.png 1366w ,https://dunghvcs.github.io/media/posts/20/responsive/WS2017-xl.png 1600w ,https://dunghvcs.github.io/media/posts/20/responsive/WS2017-2xl.png 1920w\"></figure>",
            "author": {
                "name": "Van-Dung Hoang"
            },
            "tags": [
                   "Seminars",
                   "News"
            ],
            "date_published": "2026-02-14T11:18:23+07:00",
            "date_modified": "2026-02-14T11:18:23+07:00"
        },
        {
            "id": "https://dunghvcs.github.io/summer-seminar-2023.html",
            "url": "https://dunghvcs.github.io/summer-seminar-2023.html",
            "title": "Summer Seminar 2023",
            "summary": "CVISLab- Summer seminar 2023 Knowledge representation and reasoning: Develop new models for knowledge representation, and designing knowledge bases. Reasoning methods, especially for reality applications; Ontology; Agents, multi-agent systems; Semantic Search.",
            "content_html": "<div class=\"CjVfdc CJIdie\"><span style=\"color: #169179;\"><strong><span class=\"C9DxTc \">CVISLab- Summer seminar 2023</span></strong></span></div>\n<div>Knowledge representation and reasoning: Develop new models for knowledge representation, and designing knowledge bases. Reasoning methods, especially for reality applications; Ontology; Agents, multi-agent systems; Semantic Search.</div>\n<div><figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://dunghvcs.github.io/media/posts/19/WS2023-2.png\" alt=\"\" width=\"1280\" height=\"720\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://dunghvcs.github.io/media/posts/19/responsive/WS2023-2-xs.png 640w ,https://dunghvcs.github.io/media/posts/19/responsive/WS2023-2-sm.png 768w ,https://dunghvcs.github.io/media/posts/19/responsive/WS2023-2-md.png 1024w ,https://dunghvcs.github.io/media/posts/19/responsive/WS2023-2-lg.png 1366w ,https://dunghvcs.github.io/media/posts/19/responsive/WS2023-2-xl.png 1600w ,https://dunghvcs.github.io/media/posts/19/responsive/WS2023-2-2xl.png 1920w\"></figure></div>\n<div> </div>\n<div><figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://dunghvcs.github.io/media/posts/19/WS2023_1.jpg\" alt=\"\" width=\"1280\" height=\"593\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://dunghvcs.github.io/media/posts/19/responsive/WS2023_1-xs.jpg 640w ,https://dunghvcs.github.io/media/posts/19/responsive/WS2023_1-sm.jpg 768w ,https://dunghvcs.github.io/media/posts/19/responsive/WS2023_1-md.jpg 1024w ,https://dunghvcs.github.io/media/posts/19/responsive/WS2023_1-lg.jpg 1366w ,https://dunghvcs.github.io/media/posts/19/responsive/WS2023_1-xl.jpg 1600w ,https://dunghvcs.github.io/media/posts/19/responsive/WS2023_1-2xl.jpg 1920w\"></figure></div>\n<h1 id=\"h.ev71dx2sb3hy_l\" class=\"zfr3Q duRjpb CDt4Ke \" dir=\"ltr\"></h1>",
            "author": {
                "name": "Van-Dung Hoang"
            },
            "tags": [
                   "Seminars",
                   "News"
            ],
            "date_published": "2026-02-14T11:14:13+07:00",
            "date_modified": "2026-02-14T11:14:13+07:00"
        },
        {
            "id": "https://dunghvcs.github.io/nafosted-project-2023.html",
            "url": "https://dunghvcs.github.io/nafosted-project-2023.html",
            "title": "[NAFOSTED] Project 2023: Deep learning &amp; Feature extraction",
            "summary": "Improvement of deep learning and feature extraction methods for enhancing performance of pattern recognition systems was funded by the National Foundation-NAFOSTED Today with the fast-growing of artificial intelligence (AI), intelligence systems have been strongly studied and developed accomplished outstanding results, such as in the areas of robotics, intelligent assistance systems,&hellip;",
            "content_html": "<p class=\"CjVfdc\"><span style=\"color: #169179;\"><span class=\"C9DxTc \">Improvement of deep learning and feature extraction methods for enhancing performance of pattern recognition systems was f</span><small id=\"h.mn4r8wg5orsm\" class=\"zfr3Q TMjjoe CDt4Ke \" dir=\"ltr\"><span class=\"C9DxTc \">unded by the National Foundation-N</span><span class=\"C9DxTc \">AFOSTED</span></small></span></p>\n<div>\n<p class=\"zfr3Q CDt4Ke \" dir=\"ltr\"><span class=\"C9DxTc \">Today with the fast-growing of artificial intelligence (AI), intelligence systems have been strongly studied and developed accomplished outstanding results, such as in the areas of robotics, intelligent assistance systems, medical image-based disease diagnosis, and so on. Developed machine learning methods for increasingly feature extraction, optimal model in terms of accuracy, processing speed have become a major research trend. Some research orientations in this subdomain include developing solutions to optimize deep learning models and learning hyperparameters for high discriminated feature extraction and outperformed pattern recognition. This project concentrates on studying and proposing novel approaches in machine learning techniques and feature extraction from images. The methods are designed to provide better pattern recognition in real datasets. Resulted solutions support intelligent decisions and suggestions such as recognizing diseases using visual data in medical diagnosis, detecting abnormal objects or dangerous behaviors in surveillance systems. We expect this research to be completed and contributed to the trend machine learning solutions that facilitate implementing and operating intelligent systems on resource-limited hardware to solve difficult data problems for the classification and recognition of complex objects and events. The result is toward AI technologies into practice application with acceptable costs.</span></p>\n<p class=\"zfr3Q CDt4Ke \" dir=\"ltr\"><span class=\"C9DxTc \">Develop AI technology based on deep learning models for feature extraction and pattern recognition to solve specific problems in computer vision such as image classification, object detection, medical image processing, action recognition, and scene understanding for surveillance systems. </span></p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://dunghvcs.github.io/media/posts/18/NF2.png\" alt=\"\" width=\"677\" height=\"540\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://dunghvcs.github.io/media/posts/18/responsive/NF2-xs.png 640w ,https://dunghvcs.github.io/media/posts/18/responsive/NF2-sm.png 768w ,https://dunghvcs.github.io/media/posts/18/responsive/NF2-md.png 1024w ,https://dunghvcs.github.io/media/posts/18/responsive/NF2-lg.png 1366w ,https://dunghvcs.github.io/media/posts/18/responsive/NF2-xl.png 1600w ,https://dunghvcs.github.io/media/posts/18/responsive/NF2-2xl.png 1920w\"></figure>\n</div>\n<h3 id=\"h.kujl4eg0r5ll_l\" class=\"zfr3Q OmQG5e CDt4Ke \" dir=\"ltr\"></h3>",
            "author": {
                "name": "Van-Dung Hoang"
            },
            "tags": [
                   "Researches"
            ],
            "date_published": "2026-02-14T10:30:03+07:00",
            "date_modified": "2026-02-14T10:44:56+07:00"
        },
        {
            "id": "https://dunghvcs.github.io/project-2019-melanoma-image-prediction.html",
            "url": "https://dunghvcs.github.io/project-2019-melanoma-image-prediction.html",
            "title": "Project 2019- Melanoma Image Prediction",
            "summary": "Research on Deep Neural Network Techniques for Melanoma Image Prediction: Study image analysis and processing techniques, as well as artificial intelligence methods, particularly those based on large-scale data representation and deep learning approaches. Propose solutions that apply artificial intelligence techniques to image analysis and processing, specifically for image segmentation and&hellip;",
            "content_html": "<p><strong>Research on Deep Neural Network Techniques for Melanoma Image Prediction:</strong></p>\n<ul>\n<li data-start=\"0\" data-end=\"185\">\n<p data-start=\"2\" data-end=\"185\">Study image analysis and processing techniques, as well as artificial intelligence methods, particularly those based on large-scale data representation and deep learning approaches.</p>\n</li>\n<li data-start=\"186\" data-end=\"346\">\n<p data-start=\"188\" data-end=\"346\">Propose solutions that apply artificial intelligence techniques to image analysis and processing, specifically for image segmentation and anomaly detection.</p>\n</li>\n<li data-start=\"347\" data-end=\"410\">\n<p data-start=\"349\" data-end=\"410\">Collect and select image datasets related to skin melanoma.</p>\n</li>\n<li data-start=\"411\" data-end=\"574\">\n<p data-start=\"413\" data-end=\"574\">Conduct experiments and evaluate image analysis and classification solutions for detecting pigmentation issues associated with melanoma, a type of skin cancer.</p>\n</li>\n<li data-start=\"575\" data-end=\"681\" data-is-last-node=\"\">\n<p data-start=\"577\" data-end=\"681\" data-is-last-node=\"\">Collect data, prepare research papers, present at specialized conferences, and publish research results.</p>\n</li>\n</ul>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://dunghvcs.github.io/media/posts/17/Detai_CS2018_1.png\" alt=\"\" width=\"576\" height=\"724\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://dunghvcs.github.io/media/posts/17/responsive/Detai_CS2018_1-xs.png 640w ,https://dunghvcs.github.io/media/posts/17/responsive/Detai_CS2018_1-sm.png 768w ,https://dunghvcs.github.io/media/posts/17/responsive/Detai_CS2018_1-md.png 1024w ,https://dunghvcs.github.io/media/posts/17/responsive/Detai_CS2018_1-lg.png 1366w ,https://dunghvcs.github.io/media/posts/17/responsive/Detai_CS2018_1-xl.png 1600w ,https://dunghvcs.github.io/media/posts/17/responsive/Detai_CS2018_1-2xl.png 1920w\"></figure>",
            "image": "https://dunghvcs.github.io/media/posts/17/Detai_CS2018_2.png",
            "author": {
                "name": "Van-Dung Hoang"
            },
            "tags": [
                   "Researches"
            ],
            "date_published": "2026-02-14T10:24:27+07:00",
            "date_modified": "2026-02-14T10:24:27+07:00"
        },
        {
            "id": "https://dunghvcs.github.io/project2019-virtual-tour.html",
            "url": "https://dunghvcs.github.io/project2019-virtual-tour.html",
            "title": "Project2019-Virtual tour",
            "summary": "Virtual tour development of famous places in Quang Binh using panoramic stitching, 3D interaction and modern web technology, which funded by the QB People's Committee. Collection of Tourist Site Information The research team conducted field surveys at 32 scenic and tourist destinations across Quảng Bình in accordance with the proposed&hellip;",
            "content_html": "<div class=\"CjVfdc CJIdie\"><span class=\"C9DxTc \">Virtual tour development of famous places in Quang Binh using panoramic stitching, 3D interaction and modern web technology, which funded by the QB People's Committee.</span></div>\n<div>\n<p data-start=\"0\" data-end=\"476\"><strong data-start=\"0\" data-end=\"49\">Collection of Tourist Site Information</strong><br data-start=\"49\" data-end=\"52\">The research team conducted field surveys at 32 scenic and tourist destinations across <span class=\"hover:entity-accent entity-underline inline cursor-pointer align-baseline\"><span class=\"whitespace-normal\">Quảng Bình</span></span> in accordance with the proposed research objectives and collected relevant data. The collected information includes site names, tourism types, addresses, GPS locations, and basic descriptive characteristics, which serve as reference data for the subsequent process of image and dataset collection.</p>\n<p data-start=\"478\" data-end=\"974\"><strong data-start=\"478\" data-end=\"512\">Data Collection </strong><br data-start=\"512\" data-end=\"515\">The research team carried out surveys and gathered information and written materials for 32 scenic and tourist destinations in Quảng Bình province. The collected data include descriptive information about tourist sites, associated service systems, tourism promotional articles, the number of photographs taken at each site for panoramic image construction, and images used for album creation. All data were processed to ensure adequate quantity and quality.</p>\n<p data-start=\"976\" data-end=\"1247\" data-is-last-node=\"\" data-is-only-node=\"\"><strong data-start=\"976\" data-end=\"1017\">Software System Design</strong><br data-start=\"1017\" data-end=\"1020\">The software system is designed to meet management requirements, provide information about tourist destinations, support virtual tourism experiences, display photo albums, present related services, and enable video integration.</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://dunghvcs.github.io/media/posts/16/Detai_tinh2019_1.png\" alt=\"\" width=\"842\" height=\"760\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://dunghvcs.github.io/media/posts/16/responsive/Detai_tinh2019_1-xs.png 640w ,https://dunghvcs.github.io/media/posts/16/responsive/Detai_tinh2019_1-sm.png 768w ,https://dunghvcs.github.io/media/posts/16/responsive/Detai_tinh2019_1-md.png 1024w ,https://dunghvcs.github.io/media/posts/16/responsive/Detai_tinh2019_1-lg.png 1366w ,https://dunghvcs.github.io/media/posts/16/responsive/Detai_tinh2019_1-xl.png 1600w ,https://dunghvcs.github.io/media/posts/16/responsive/Detai_tinh2019_1-2xl.png 1920w\"></figure>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://dunghvcs.github.io/media/posts/16/Detai_tinh2019_2.png\" alt=\"\" width=\"1168\" height=\"774\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://dunghvcs.github.io/media/posts/16/responsive/Detai_tinh2019_2-xs.png 640w ,https://dunghvcs.github.io/media/posts/16/responsive/Detai_tinh2019_2-sm.png 768w ,https://dunghvcs.github.io/media/posts/16/responsive/Detai_tinh2019_2-md.png 1024w ,https://dunghvcs.github.io/media/posts/16/responsive/Detai_tinh2019_2-lg.png 1366w ,https://dunghvcs.github.io/media/posts/16/responsive/Detai_tinh2019_2-xl.png 1600w ,https://dunghvcs.github.io/media/posts/16/responsive/Detai_tinh2019_2-2xl.png 1920w\"></figure>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://dunghvcs.github.io/media/posts/16/IMG-0366.JPG\" alt=\"\" width=\"1366\" height=\"768\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://dunghvcs.github.io/media/posts/16/responsive/IMG-0366-xs.JPG 640w ,https://dunghvcs.github.io/media/posts/16/responsive/IMG-0366-sm.JPG 768w ,https://dunghvcs.github.io/media/posts/16/responsive/IMG-0366-md.JPG 1024w ,https://dunghvcs.github.io/media/posts/16/responsive/IMG-0366-lg.JPG 1366w ,https://dunghvcs.github.io/media/posts/16/responsive/IMG-0366-xl.JPG 1600w ,https://dunghvcs.github.io/media/posts/16/responsive/IMG-0366-2xl.JPG 1920w\"></figure>\n</div>\n<div> </div>\n<h3 id=\"h.fklu04cvv6wh_l\" class=\"zfr3Q OmQG5e CDt4Ke \" dir=\"ltr\"></h3>",
            "image": "https://dunghvcs.github.io/media/posts/16/Tinh2-2.png",
            "author": {
                "name": "Van-Dung Hoang"
            },
            "tags": [
                   "Researches"
            ],
            "date_published": "2026-02-14T10:15:14+07:00",
            "date_modified": "2026-02-14T10:15:14+07:00"
        },
        {
            "id": "https://dunghvcs.github.io/project-2015-funded-by-the-qb-peoples-committee.html",
            "url": "https://dunghvcs.github.io/project-2015-funded-by-the-qb-peoples-committee.html",
            "title": "Project 2015- Surveillance Systems",
            "summary": "Proposal a computer vision- based surveillance system applied to secured to office building in Quang Binh province was funded by the QB People's Committee. General Objectives: To investigate and analyze the current state of technology applications in ensuring security for socio-economic development. To propose a real-time security recognition, tracking, and&hellip;",
            "content_html": "<div class=\"CjVfdc\"><span class=\"C9DxTc \">Proposal a computer vision- based surveillance system applied to secured to office building in Quang Binh province was funded by the QB People's Committee.</span></div>\n<div>\n<p data-start=\"0\" data-end=\"25\"><strong data-start=\"0\" data-end=\"23\">General Objectives:</strong></p>\n<ul data-start=\"26\" data-end=\"258\">\n<li data-start=\"26\" data-end=\"154\">\n<p data-start=\"28\" data-end=\"154\">To investigate and analyze the current state of technology applications in ensuring security for socio-economic development.</p>\n</li>\n<li data-start=\"155\" data-end=\"258\">\n<p data-start=\"157\" data-end=\"258\">To propose a real-time security recognition, tracking, and alert system model for office buildings.</p>\n</li>\n</ul>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://dunghvcs.github.io/media/posts/15/tinh1.png\" alt=\"\" width=\"1038\" height=\"1086\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://dunghvcs.github.io/media/posts/15/responsive/tinh1-xs.png 640w ,https://dunghvcs.github.io/media/posts/15/responsive/tinh1-sm.png 768w ,https://dunghvcs.github.io/media/posts/15/responsive/tinh1-md.png 1024w ,https://dunghvcs.github.io/media/posts/15/responsive/tinh1-lg.png 1366w ,https://dunghvcs.github.io/media/posts/15/responsive/tinh1-xl.png 1600w ,https://dunghvcs.github.io/media/posts/15/responsive/tinh1-2xl.png 1920w\"></figure>\n<p data-start=\"260\" data-end=\"286\"><strong data-start=\"260\" data-end=\"284\">Specific Objectives:</strong></p>\n<ul data-start=\"287\" data-end=\"888\">\n<li data-start=\"287\" data-end=\"334\">\n<p data-start=\"289\" data-end=\"334\">To retrieve data from surveillance cameras.</p>\n</li>\n<li data-start=\"335\" data-end=\"699\">\n<p data-start=\"337\" data-end=\"372\">Recognition and tracking methods:</p>\n<ul data-start=\"375\" data-end=\"699\">\n<li data-start=\"375\" data-end=\"424\">\n<p data-start=\"377\" data-end=\"424\">Propose image feature representation methods.</p>\n</li>\n<li data-start=\"427\" data-end=\"491\">\n<p data-start=\"429\" data-end=\"491\">Propose models for target objects to be recognized (humans).</p>\n</li>\n<li data-start=\"494\" data-end=\"568\">\n<p data-start=\"496\" data-end=\"568\">Propose artificial intelligence frameworks for training object models.</p>\n</li>\n<li data-start=\"571\" data-end=\"639\">\n<p data-start=\"573\" data-end=\"639\">Propose and develop systems for object recognition and tracking.</p>\n</li>\n<li data-start=\"642\" data-end=\"699\">\n<p data-start=\"644\" data-end=\"699\">Build datasets for training, evaluation, and testing.</p>\n</li>\n</ul>\n</li>\n<li data-start=\"701\" data-end=\"839\">\n<p data-start=\"703\" data-end=\"722\"><strong data-start=\"703\" data-end=\"720\">Alert System:</strong></p>\n<ul data-start=\"725\" data-end=\"839\">\n<li data-start=\"725\" data-end=\"781\">\n<p data-start=\"727\" data-end=\"781\">Analyze and develop semantic representation systems.</p>\n</li>\n<li data-start=\"784\" data-end=\"839\">\n<p data-start=\"786\" data-end=\"839\">Build decision-support systems for security alerts.</p>\n</li>\n</ul>\n</li>\n<li data-start=\"841\" data-end=\"888\">\n<p data-start=\"843\" data-end=\"888\">Conduct system experiments and evaluations.</p>\n</li>\n</ul>\n<p data-start=\"890\" data-end=\"919\"><strong data-start=\"890\" data-end=\"917\">Research Subjects:</strong></p>\n<ul data-start=\"920\" data-end=\"1131\" data-is-last-node=\"\" data-is-only-node=\"\">\n<li data-start=\"920\" data-end=\"984\">\n<p data-start=\"922\" data-end=\"984\">Suspicious individuals illegally entering office facilities.</p>\n</li>\n<li data-start=\"985\" data-end=\"1059\">\n<p data-start=\"987\" data-end=\"1059\">Image processing, feature representation, and artificial intelligence.</p>\n</li>\n<li data-start=\"1060\" data-end=\"1131\" data-is-last-node=\"\">\n<p data-start=\"1062\" data-end=\"1131\" data-is-last-node=\"\">Expert systems and contextual reasoning applied to security alerting.</p>\n</li>\n</ul>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://dunghvcs.github.io/media/posts/15/IMG_2418.jpg\" alt=\"\" width=\"2542\" height=\"974\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://dunghvcs.github.io/media/posts/15/responsive/IMG_2418-xs.jpg 640w ,https://dunghvcs.github.io/media/posts/15/responsive/IMG_2418-sm.jpg 768w ,https://dunghvcs.github.io/media/posts/15/responsive/IMG_2418-md.jpg 1024w ,https://dunghvcs.github.io/media/posts/15/responsive/IMG_2418-lg.jpg 1366w ,https://dunghvcs.github.io/media/posts/15/responsive/IMG_2418-xl.jpg 1600w ,https://dunghvcs.github.io/media/posts/15/responsive/IMG_2418-2xl.jpg 1920w\"></figure>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://dunghvcs.github.io/media/posts/15/IMG_2371.jpg\" alt=\"\" width=\"2592\" height=\"1339\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://dunghvcs.github.io/media/posts/15/responsive/IMG_2371-xs.jpg 640w ,https://dunghvcs.github.io/media/posts/15/responsive/IMG_2371-sm.jpg 768w ,https://dunghvcs.github.io/media/posts/15/responsive/IMG_2371-md.jpg 1024w ,https://dunghvcs.github.io/media/posts/15/responsive/IMG_2371-lg.jpg 1366w ,https://dunghvcs.github.io/media/posts/15/responsive/IMG_2371-xl.jpg 1600w ,https://dunghvcs.github.io/media/posts/15/responsive/IMG_2371-2xl.jpg 1920w\"></figure>\n</div>\n<h3 id=\"h.o4ldey3lih43_l\" class=\"zfr3Q OmQG5e CDt4Ke \" dir=\"ltr\"></h3>",
            "image": "https://dunghvcs.github.io/media/posts/15/IMG_2346.jpg",
            "author": {
                "name": "Van-Dung Hoang"
            },
            "tags": [
                   "Researches"
            ],
            "date_published": "2026-02-14T10:02:05+07:00",
            "date_modified": "2026-02-14T10:25:57+07:00"
        },
        {
            "id": "https://dunghvcs.github.io/ulsan2023-visiting-research.html",
            "url": "https://dunghvcs.github.io/ulsan2023-visiting-research.html",
            "title": "Ulsan2023 - Visiting research",
            "summary": "Visiting research at Ulsan ISLab (Intelligent Systems Laboratory) in 2023, led by Professor Kang-Hyun Jo, focuses heavily on advanced computer vision applications, including generative models, 3D reconstruction, autonomous driving systems, and human motion/gait analysis. Key areas often involve 3D facial landmark detection and intelligent video systems.",
            "content_html": "<p>Visiting research at <span data-wiz-uids=\"EvebVb_b\" data-processed=\"true\"><a jsuid=\"EvebVb_b\" class=\"GI370e\" data-ved=\"2ahUKEwiKr_u4_deSAxXbcPUHHZWdB98QgK4QegQIARAB\" data-hveid=\"CAEQAQ\" data-processed=\"true\" href=\"https://www.google.com/search?q=Ulsan+ISLab&amp;sca_esv=4e4f828e227a99b7&amp;rlz=1C1YTUH_viVN1067VN1067&amp;biw=1920&amp;bih=911&amp;sxsrf=ANbL-n5v7v0nqWMcvqe6sEudzB43FR2XTg%3A1771037561148&amp;ei=eeOPaZrgCI7i2roPsLDa-QI&amp;ved=2ahUKEwiKr_u4_deSAxXbcPUHHZWdB98QgK4QegQIARAB&amp;uact=5&amp;oq=visiting+research+at+Ulsan+Islab+2023++on+Compuiter+vision+topic&amp;gs_lp=Egxnd3Mtd2l6LXNlcnAiQHZpc2l0aW5nIHJlc2VhcmNoIGF0IFVsc2FuIElzbGFiIDIwMjMgIG9uIENvbXB1aXRlciB2aXNpb24gdG9waWNIjrgBUNwHWMW2AXALeACQAQSYAd8BoAHfOqoBBjIuNTQuMbgBA8gBAPgBAZgCOaACvzDCAgoQABiwAxjWBBhHwgIFECEYoAHCAgYQABgWGB7CAgsQABiABBiGAxiKBcICBRAAGO8FwgIIEAAYgAQYogTCAgQQIxgnwgIIEAAYFhgKGB7CAgsQABiABBiRAhiKBcICBRAAGIAEwgIHECEYoAEYCsICBBAhGBXCAgQQIRgKwgIGECEYFRgKmAMAiAYBkAYIkgcFMTIuNDWgB_X7AbIHBDEuNDW4B5AwwgcJMy4zNS4xOC4xyAebAYAIAA&amp;sclient=gws-wiz-serp\">Ulsan ISLab</a></span> (Intelligent Systems Laboratory) in 2023, led by Professor Kang-Hyun Jo, focuses heavily on advanced computer vision applications, including generative models, 3D reconstruction, autonomous driving systems, and human motion/gait analysis. Key areas often involve 3D facial landmark detection and intelligent video systems.<span class=\"uJ19be notranslate\" data-wiz-uids=\"EvebVb_d,EvebVb_e\" data-processed=\"true\"><span class=\"vKEkVd\" data-animation-atomic=\"\" data-wiz-attrbind=\"class=EvebVb_c/TKHnVd\" data-processed=\"true\"><span aria-hidden=\"true\" data-processed=\"true\"> </span></span></span></p>\n<ul class=\"KsbFXc U6u95\" data-processed=\"true\">\n<li data-hveid=\"CAMQAA\" data-processed=\"true\"><span class=\"T286Pc\" data-sfc-cp=\"\" data-processed=\"true\"><strong class=\"Yjhzub\" data-processed=\"true\">3D Vision and Reconstruction:</strong> Techniques for scene modeling and 3D pose estimation.</span></li>\n<li data-hveid=\"CAMQAQ\" data-processed=\"true\"><span class=\"T286Pc\" data-sfc-cp=\"\" data-processed=\"true\"><strong class=\"Yjhzub\" data-processed=\"true\">Intelligent Transportation/Driving:</strong> Computer vision algorithms for autonomous vehicles and event detection.</span></li>\n<li data-hveid=\"CAMQAg\" data-processed=\"true\"><span class=\"T286Pc\" data-sfc-cp=\"\" data-processed=\"true\"><strong class=\"Yjhzub\" data-processed=\"true\">Computer Vision &amp; AI:</strong> Deep learning techniques for image understanding, object detection, and tracking.</span></li>\n<li data-hveid=\"CAMQAw\" data-processed=\"true\"><span class=\"T286Pc\" data-sfc-cp=\"\" data-processed=\"true\"><strong class=\"Yjhzub\" data-processed=\"true\">Human Motion Analysis:</strong> Analyzing gait and human movement for recognition task</span></li>\n</ul>\n<p> </p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://dunghvcs.github.io/media/posts/14/Ulsan20231_2.jpg\" alt=\"\" width=\"2560\" height=\"1152\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://dunghvcs.github.io/media/posts/14/responsive/Ulsan20231_2-xs.jpg 640w ,https://dunghvcs.github.io/media/posts/14/responsive/Ulsan20231_2-sm.jpg 768w ,https://dunghvcs.github.io/media/posts/14/responsive/Ulsan20231_2-md.jpg 1024w ,https://dunghvcs.github.io/media/posts/14/responsive/Ulsan20231_2-lg.jpg 1366w ,https://dunghvcs.github.io/media/posts/14/responsive/Ulsan20231_2-xl.jpg 1600w ,https://dunghvcs.github.io/media/posts/14/responsive/Ulsan20231_2-2xl.jpg 1920w\"></figure>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://dunghvcs.github.io/media/posts/14/Ulsan20231_1-2.JPG\" alt=\"\" width=\"4032\" height=\"3024\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://dunghvcs.github.io/media/posts/14/responsive/Ulsan20231_1-2-xs.JPG 640w ,https://dunghvcs.github.io/media/posts/14/responsive/Ulsan20231_1-2-sm.JPG 768w ,https://dunghvcs.github.io/media/posts/14/responsive/Ulsan20231_1-2-md.JPG 1024w ,https://dunghvcs.github.io/media/posts/14/responsive/Ulsan20231_1-2-lg.JPG 1366w ,https://dunghvcs.github.io/media/posts/14/responsive/Ulsan20231_1-2-xl.JPG 1600w ,https://dunghvcs.github.io/media/posts/14/responsive/Ulsan20231_1-2-2xl.JPG 1920w\"></figure>",
            "author": {
                "name": "Van-Dung Hoang"
            },
            "tags": [
                   "News"
            ],
            "date_published": "2026-02-14T09:56:24+07:00",
            "date_modified": "2026-02-14T11:20:24+07:00"
        },
        {
            "id": "https://dunghvcs.github.io/aciids2023.html",
            "url": "https://dunghvcs.github.io/aciids2023.html",
            "title": "ACIIDS2023",
            "summary": "ACIIDS 2023 is an international scientific conference for research in the field of intelligent information and database systems, held from 24 to 26 of July 2023 in Phuket, Thailand. The conference aims to provide an internationally respected forum for scientific research in intelligent information and database systems technologies and applications.",
            "content_html": "<p>ACIIDS 2023 is an international scientific conference for research in the field of intelligent information and database systems, held from 24 to 26 of July 2023 in Phuket, Thailand.</p>\n<p>The conference aims to provide an internationally respected forum for scientific research in intelligent information and database systems technologies and applications. ACIIDS conference is ranked category B in the prestigious <a href=\"http://portal.core.edu.au/conf-ranks/2188/\">CORE ranking</a>.</p>\n<p>The conference is hosted by King Mongkut’s Institute of Technology Ladkrabang, Thailand, and jointly organized by Wrocław University of Science and Technology, Poland, in cooperation with IEEE SMC Technical Committee on Computational Collective Intelligence, European Research Center for Information Systems (ERCIS), University of Newcastle (Australia), Yeungnam University (Korea), International University - Vietnam National University HCMC (Vietnam), Leiden University (The Netherlands), Universiti Teknologi Malaysia (Malaysia), Ton Duc Thang University (Vietnam), BINUS University (Indonesia), and Vietnam National University, Hanoi (Vietnam).</p>\n<p>The proceedings of ACIIDS 2023 will be published by Springer.</p>\n<p class=\"zfr3Q CDt4Ke \" dir=\"ltr\"><span class=\"C9DxTc \">CVISLab member presents a contribution on \"Combination of Deep Learning and Ambiguity Rejection for Improving Image-Based Disease Diagnosis\".</span></p>\n<p class=\"zfr3Q CDt4Ke \" dir=\"ltr\"><span class=\"C9DxTc \">A leader of CVISLab achieves outstanding contribution award for 15 Years of ACIIDS conference</span></p>\n<p class=\"zfr3Q CDt4Ke \" dir=\"ltr\"><span class=\"C9DxTc \">Over all, everything is well organized.</span></p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://dunghvcs.github.io/media/posts/13/ACIIDS2023_2.jpg\" alt=\"\" width=\"1280\" height=\"1818\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://dunghvcs.github.io/media/posts/13/responsive/ACIIDS2023_2-xs.jpg 640w ,https://dunghvcs.github.io/media/posts/13/responsive/ACIIDS2023_2-sm.jpg 768w ,https://dunghvcs.github.io/media/posts/13/responsive/ACIIDS2023_2-md.jpg 1024w ,https://dunghvcs.github.io/media/posts/13/responsive/ACIIDS2023_2-lg.jpg 1366w ,https://dunghvcs.github.io/media/posts/13/responsive/ACIIDS2023_2-xl.jpg 1600w ,https://dunghvcs.github.io/media/posts/13/responsive/ACIIDS2023_2-2xl.jpg 1920w\"></figure>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://dunghvcs.github.io/media/posts/13/ACIIDS2023_1.jpg\" alt=\"\" width=\"959\" height=\"539\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://dunghvcs.github.io/media/posts/13/responsive/ACIIDS2023_1-xs.jpg 640w ,https://dunghvcs.github.io/media/posts/13/responsive/ACIIDS2023_1-sm.jpg 768w ,https://dunghvcs.github.io/media/posts/13/responsive/ACIIDS2023_1-md.jpg 1024w ,https://dunghvcs.github.io/media/posts/13/responsive/ACIIDS2023_1-lg.jpg 1366w ,https://dunghvcs.github.io/media/posts/13/responsive/ACIIDS2023_1-xl.jpg 1600w ,https://dunghvcs.github.io/media/posts/13/responsive/ACIIDS2023_1-2xl.jpg 1920w\"></figure>",
            "author": {
                "name": "Van-Dung Hoang"
            },
            "tags": [
                   "Conference Events"
            ],
            "date_published": "2026-02-14T09:52:08+07:00",
            "date_modified": "2026-02-14T09:52:08+07:00"
        },
        {
            "id": "https://dunghvcs.github.io/icsse-2023.html",
            "url": "https://dunghvcs.github.io/icsse-2023.html",
            "title": "ICSSE 2023",
            "summary": "ICSSE 2023: The Annual International Conference on System Science and Engineering, well known as ICSSE, is a reputational conference on System Science and Engineering area. ICSSE 2023, hosted by Ho Chi Minh City University of Technology and Education (Vietnam), Taiwan Association of System Science and Engineering (TASSE), National Taiwan Ocean University&hellip;",
            "content_html": "<p class=\"zfr3Q CDt4Ke \" dir=\"ltr\"><span class=\"C9DxTc \"><span style=\"color: #e03e2d;\"><strong><span style=\"color: #2dc26b;\">ICSSE 2023:</span> </strong></span></span>The Annual International Conference on System Science and Engineering, well known as ICSSE, is a reputational conference on System Science and Engineering area.  ICSSE 2023, hosted by Ho Chi Minh City University of Technology and Education (Vietnam), Taiwan Association of System Science and Engineering (TASSE), National Taiwan Ocean University (Taiwan) and Rajamangala University of Technology Lanna (Thailand), will take place in Ho Chi Minh City, Vietnam during July 27-28, 2023.  The scholars, experts, engineers, and practitioners from all over the world are warmly invited to present the latest enhancements and innovations in the field of system science and engineering, as well as to facilitate interactions between scholars and practitioners. ICSSE 2023 will feature plenary speeches in emerging technology topics given by world renowned scholars. The conference welcomes all submissions of original research papers in all aspects of System Science and Engineering as listed below. The papers will go through a thorough and strict peer-review process in IEEE standards.</p>\n<p dir=\"ltr\">System Science and Engineering is a research area that covers a wide spectrum of modern technologies. A system includes a collection of entities and their interrelationships to jointly form a whole greater than the sum of the entities. It also involves human, organizations, cultures, activities and interrelationships. Nowadays, systems composed of autonomous subsystems are more and more widely used and show the great advantages of expanded data density, connectivity, and ubiquitous computational resources with higher interdependence and interaction complexity. This has in turn made the job of planning, developing and deploying complex systems even more difficult and intelligent.</p>\n<p class=\"zfr3Q CDt4Ke \" dir=\"ltr\"><span class=\"C9DxTc \">CVISLab member presents a contribution on \"</span><span class=\"C9DxTc \">Fusion of ViT Technique and Image Filtering in Deep Learning for Plant Pests and Diseases Recognition</span><span class=\"C9DxTc \">\".</span></p>\n<p class=\"zfr3Q CDt4Ke \" dir=\"ltr\"><span class=\"C9DxTc \">Over all, everything is well organized.</span></p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://dunghvcs.github.io/media/posts/12/ICSSE2023_1.JPG\" alt=\"\" width=\"1280\" height=\"798\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://dunghvcs.github.io/media/posts/12/responsive/ICSSE2023_1-xs.JPG 640w ,https://dunghvcs.github.io/media/posts/12/responsive/ICSSE2023_1-sm.JPG 768w ,https://dunghvcs.github.io/media/posts/12/responsive/ICSSE2023_1-md.JPG 1024w ,https://dunghvcs.github.io/media/posts/12/responsive/ICSSE2023_1-lg.JPG 1366w ,https://dunghvcs.github.io/media/posts/12/responsive/ICSSE2023_1-xl.JPG 1600w ,https://dunghvcs.github.io/media/posts/12/responsive/ICSSE2023_1-2xl.JPG 1920w\"></figure>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://dunghvcs.github.io/media/posts/12/ICSSE2023_2.JPG\" alt=\"\" width=\"960\" height=\"721\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://dunghvcs.github.io/media/posts/12/responsive/ICSSE2023_2-xs.JPG 640w ,https://dunghvcs.github.io/media/posts/12/responsive/ICSSE2023_2-sm.JPG 768w ,https://dunghvcs.github.io/media/posts/12/responsive/ICSSE2023_2-md.JPG 1024w ,https://dunghvcs.github.io/media/posts/12/responsive/ICSSE2023_2-lg.JPG 1366w ,https://dunghvcs.github.io/media/posts/12/responsive/ICSSE2023_2-xl.JPG 1600w ,https://dunghvcs.github.io/media/posts/12/responsive/ICSSE2023_2-2xl.JPG 1920w\"></figure>",
            "author": {
                "name": "Van-Dung Hoang"
            },
            "tags": [
                   "Conference Events"
            ],
            "date_published": "2026-02-14T09:49:20+07:00",
            "date_modified": "2026-02-14T09:49:20+07:00"
        },
        {
            "id": "https://dunghvcs.github.io/fair-2023.html",
            "url": "https://dunghvcs.github.io/fair-2023.html",
            "title": "FAIR 2023",
            "summary": "FAIR - Fundamental and Applied Information Technology Liên hiệp các Hội Khoa học và Kỹ thuật Việt Nam, Viện Hàn lâm Khoa học và Công nghệ Việt Nam phối hợp cùng Trường Đại học Công nghiệp Hà Nội và các cơ quan khoa học, các nhà khoa học từ các viện nghiên&hellip;",
            "content_html": "<p class=\"zfr3Q CDt4Ke \" dir=\"ltr\"><span style=\"color: #169179;\"><strong><span class=\"C9DxTc \">FAIR - Fundamental and Applied Information Technology</span><span class=\"C9DxTc \"> </span></strong></span></p>\n<p>Liên hiệp các Hội Khoa học và Kỹ thuật Việt Nam, Viện Hàn lâm Khoa học và Công nghệ Việt Nam phối hợp cùng <span class=\"fontstyle0\">Trường Đại học Công nghiệp Hà Nội </span>và các cơ quan khoa học, các nhà khoa học từ các viện nghiên cứu, các trường đại học để tổ chức Hội nghị khoa học quốc gia lần thứ XVIII về \"Nghiên cứu cơ bản và ứng dụng Công nghệ thông tin\".</p>\n<p dir=\"ltr\">Chủ đề chính của Hội nghị là \" <span class=\"fontstyle0\">Chuyển đổi số và các xu thế tương lai</span>\". Tuy nhiên, do truyền thống của Hội nghị nên không hạn chế về nội dung. Hội nghị năm nay được sự bảo trợ chuyên môn của 4 cơ sở đào tạo uy tín trong lĩnh vực công nghệ thông tin – truyền thông là Đại học Đà Nẵng, Học viện Công nghệ Bưu chính Viễn thông, Trường Đại hoc Công nghệ Thông tin &amp; Truyền thông Thái Nguyên, Viện Công nghệ Thông tin – ĐHQGHN.<br>FAIR lần thứ XVIII (FAIR'2025), tổ chức tại Trường Đại học Công nghiệp Hà Nội vào 2 ngày: Thứ Năm và Thứ Sáu, 21 - 22/08/2025.</p>\n<div class=\"gallery-wrapper\"><div class=\"gallery\" data-is-empty=\"false\" data-translation=\"Add images\" data-columns=\"3\">\n<figure class=\"gallery__item\"><a href=\"https://dunghvcs.github.io/media/posts/11/gallery/FAIR2023_1.jpg\" data-size=\"1163x960\"><img loading=\"lazy\" src=\"https://dunghvcs.github.io/media/posts/11/gallery/FAIR2023_1-thumbnail.jpg\" alt=\"\" width=\"720\" height=\"594\"></a></figure>\n<figure class=\"gallery__item\"><a href=\"https://dunghvcs.github.io/media/posts/11/gallery/FAIR2023_2.jpg\" data-size=\"917x515\"><img loading=\"lazy\" src=\"https://dunghvcs.github.io/media/posts/11/gallery/FAIR2023_2-thumbnail.jpg\" alt=\"\" width=\"720\" height=\"404\"></a></figure>\n</div></div>\n<p class=\"zfr3Q CDt4Ke \" dir=\"ltr\"><span class=\"C9DxTc \">CVISLab member presents a contribution on \"Performance Evaluation of Mediapipe and Openpose for Skeleton Data Extraction\"</span></p>\n<p class=\"zfr3Q CDt4Ke \" dir=\"ltr\"><span class=\"C9DxTc \">In this study, our focus lies in evaluating two approaches for extracting skeletal data based on OpenPose and Mediapipe frameworks across the KTH and UTD-MHAD datasets. The skeletal data extracted from both methods serves as input for the AcTv2 model, an enhanced version of the AcT model. Through training and evaluating on the AcTv2 model, we ascertain the effectiveness of both skeletal data extraction methods on specific datasets. The experimental results of this research contribute to a better understanding of the efficacy of these skeletal data extraction methods in providing informative data for the AcTv2 model to recognize human actions across different datasets.</span></p>",
            "image": "https://dunghvcs.github.io/media/posts/11/FAIR2023_2.jpg",
            "author": {
                "name": "Van-Dung Hoang"
            },
            "tags": [
                   "Conference Events"
            ],
            "date_published": "2026-02-14T09:34:04+07:00",
            "date_modified": "2026-02-14T09:34:34+07:00"
        }
    ]
}
