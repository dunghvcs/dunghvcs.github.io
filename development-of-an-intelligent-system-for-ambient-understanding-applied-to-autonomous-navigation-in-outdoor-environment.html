<!DOCTYPE html><html lang="en-gb"><head><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>[NAFOSTED] Project ambient understanding - dunghv.github.io</title><meta name="description" content="Development of an intelligent system for ambient understanding applied to autonomous navigation in outdoor environment.  This project proposes and studies a novel method that improves efficiency of scene understanding, which is useful for autonomous navigation, based on the multiple sensors-based. The method is expected to provide the better scene understanding, which then allows a robot to avoid obstacles in front of its navigation. The method consists of some stages. First, a path planning is investigated, which concerns about the findings of the efficient path to facilitate the autonomous driving. The second is referred to the problem of the motion estimation and the localization prediction of running vehicle. It is addressed based on applying the fusion of cameras, LRF and GPS devices. Our research proposes a new method that uses the minimal set of parameters consisting of the geometrical constraints for estimating the 3D motion of vehicle using cameras and LRF. The cumulative errors of visual odometry are excluded using the GPS-based correction relied on the maximum likelihood estimation in particle filter. The semantic of object classification and detection are also studied. The obstacle detection, place recognition techniques are used as a solution to assisting the autonomous driver. We focus on dealing with detecting obstacles that commonly occur such as pedestrians and vehicles. The place recognition is also considered for scene understanding and mapping. We introduce improving of feature descriptors, deformable part model as well hybrid boosting SVM and neural network. "><meta name="generator" content="Publii Open-Source CMS for Static Site"><link rel="canonical" href="https://dunghvcs.github.io/development-of-an-intelligent-system-for-ambient-understanding-applied-to-autonomous-navigation-in-outdoor-environment.html"><link rel="alternate" type="application/atom+xml" href="https://dunghvcs.github.io/feed.xml" title="dunghv.github.io - RSS"><link rel="alternate" type="application/json" href="https://dunghvcs.github.io/feed.json" title="dunghv.github.io - JSON"><meta property="og:title" content="[NAFOSTED] Project ambient understanding"><meta property="og:image" content="https://dunghvcs.github.io/media/website/CVISLab.png"><meta property="og:image:width" content="816"><meta property="og:image:height" content="328"><meta property="og:site_name" content="dunghv.github.io"><meta property="og:description" content="Development of an intelligent system for ambient understanding applied to autonomous navigation in outdoor environment.  This project proposes and studies a novel method that improves efficiency of scene understanding, which is useful for autonomous navigation, based on the multiple sensors-based. The method is expected to provide the better scene understanding, which then allows a robot to avoid obstacles in front of its navigation. The method consists of some stages. First, a path planning is investigated, which concerns about the findings of the efficient path to facilitate the autonomous driving. The second is referred to the problem of the motion estimation and the localization prediction of running vehicle. It is addressed based on applying the fusion of cameras, LRF and GPS devices. Our research proposes a new method that uses the minimal set of parameters consisting of the geometrical constraints for estimating the 3D motion of vehicle using cameras and LRF. The cumulative errors of visual odometry are excluded using the GPS-based correction relied on the maximum likelihood estimation in particle filter. The semantic of object classification and detection are also studied. The obstacle detection, place recognition techniques are used as a solution to assisting the autonomous driver. We focus on dealing with detecting obstacles that commonly occur such as pedestrians and vehicles. The place recognition is also considered for scene understanding and mapping. We introduce improving of feature descriptors, deformable part model as well hybrid boosting SVM and neural network. "><meta property="og:url" content="https://dunghvcs.github.io/development-of-an-intelligent-system-for-ambient-understanding-applied-to-autonomous-navigation-in-outdoor-environment.html"><meta property="og:type" content="article"><link rel="shortcut icon" href="https://dunghvcs.github.io/media/website/CVIS.png" type="image/x-icon"><link rel="stylesheet" href="https://dunghvcs.github.io/assets/css/style.css?v=a0617c009b6e37811afe04eb08265400"><script type="application/ld+json">{"@context":"http://schema.org","@type":"Article","mainEntityOfPage":{"@type":"WebPage","@id":"https://dunghvcs.github.io/development-of-an-intelligent-system-for-ambient-understanding-applied-to-autonomous-navigation-in-outdoor-environment.html"},"headline":"[NAFOSTED] Project ambient understanding","datePublished":"2026-02-13T10:18+07:00","dateModified":"2026-02-13T11:25+07:00","image":{"@type":"ImageObject","url":"https://dunghvcs.github.io/media/website/CVISLab.png","height":328,"width":816},"description":"Development of an intelligent system for ambient understanding applied to autonomous navigation in outdoor environment.  This project proposes and studies a novel method that improves efficiency of scene understanding, which is useful for autonomous navigation, based on the multiple sensors-based. The method is expected to provide the better scene understanding, which then allows a robot to avoid obstacles in front of its navigation. The method consists of some stages. First, a path planning is investigated, which concerns about the findings of the efficient path to facilitate the autonomous driving. The second is referred to the problem of the motion estimation and the localization prediction of running vehicle. It is addressed based on applying the fusion of cameras, LRF and GPS devices. Our research proposes a new method that uses the minimal set of parameters consisting of the geometrical constraints for estimating the 3D motion of vehicle using cameras and LRF. The cumulative errors of visual odometry are excluded using the GPS-based correction relied on the maximum likelihood estimation in particle filter. The semantic of object classification and detection are also studied. The obstacle detection, place recognition techniques are used as a solution to assisting the autonomous driver. We focus on dealing with detecting obstacles that commonly occur such as pedestrians and vehicles. The place recognition is also considered for scene understanding and mapping. We introduce improving of feature descriptors, deformable part model as well hybrid boosting SVM and neural network. ","author":{"@type":"Person","name":"Van-Dung Hoang","url":"https://dunghvcs.github.io/authors/van-dung-hoang/"},"publisher":{"@type":"Organization","name":"Van-Dung Hoang","logo":{"@type":"ImageObject","url":"https://dunghvcs.github.io/media/website/CVISLab.png","height":328,"width":816}}}</script><noscript><style>img[loading] {
                    opacity: 1;
                }</style></noscript></head><body class="post-template"><header class="top js-header"><a class="logo" href="https://dunghvcs.github.io/"><img src="https://dunghvcs.github.io/media/website/CVISLab.png" alt="dunghv.github.io" width="816" height="328"></a><nav class="navbar js-navbar"><button class="navbar__toggle js-toggle" aria-label="Menu" aria-haspopup="true" aria-expanded="false"><span class="navbar__toggle-box"><span class="navbar__toggle-inner">Menu</span></span></button><ul class="navbar__menu"><li><a href="https://dunghvcs.github.io/" target="_self">Home</a></li><li class="has-submenu"><a href="https://dunghvcs.github.io/tags/newsconf/" target="_self" aria-haspopup="true">News</a><ul class="navbar__submenu level-2" aria-hidden="true"><li><a href="https://dunghvcs.github.io/tags/newsconf/" target="_self">Conference events</a></li><li><a href="https://dunghvcs.github.io/tags/seminar/" target="_self">Seminars</a></li></ul></li><li><a href="https://dunghvcs.github.io/tags/courses/" target="_self">Courses</a></li><li><a href="https://dunghvcs.github.io/tags/research/" target="_self">Research</a></li><li><a href="https://dunghvcs.github.io/publications.html" target="_self">Publications</a></li><li><a href="https://dunghvcs.github.io/" target="_self">Dataset</a></li><li><a href="https://dunghvcs.github.io/get-in-tourch.html" target="_self">Contact</a></li><li><a href="https://dunghvcs.github.io/about.html" target="_self">About</a></li></ul></nav></header><main class="post"><article class="content"><div class="hero hero--noimage"><header class="hero__content"><div class="wrapper"><h1>[NAFOSTED] Project ambient understanding</h1></div></header></div><div class="entry-wrapper content__entry"><h2><span style="color: #169179;"><strong><span style="color: #169179;">Development of an intelligent system for ambient understanding applied to autonomous navigation in outdoor environment.</span>  </strong></span></h2><p>This project proposes and studies a novel method that improves efficiency of scene understanding, which is useful for autonomous navigation, based on the multiple sensors-based. The method is expected to provide the better scene understanding, which then allows a robot to avoid obstacles in front of its navigation. The method consists of some stages. First, a path planning is investigated, which concerns about the findings of the efficient path to facilitate the autonomous driving. The second is referred to the problem of the motion estimation and the localization prediction of running vehicle. It is addressed based on applying the fusion of cameras, LRF and GPS devices. Our research proposes a new method that uses the minimal set of parameters consisting of the geometrical constraints for estimating the 3D motion of vehicle using cameras and LRF. The cumulative errors of visual odometry are excluded using the GPS-based correction relied on the maximum likelihood estimation in particle filter. The semantic of object classification and detection are also studied. The obstacle detection, place recognition techniques are used as a solution to assisting the autonomous driver. We focus on dealing with detecting obstacles that commonly occur such as pedestrians and vehicles. The place recognition is also considered for scene understanding and mapping. We introduce improving of feature descriptors, deformable part model as well hybrid boosting SVM and neural network. </p><div class="gallery-wrapper"><div class="gallery" data-is-empty="false" data-translation="Add images" data-columns="3"><figure class="gallery__item"><a href="https://dunghvcs.github.io/media/posts/5//gallery/NF1.png" data-size="956x916"><img loading="lazy" src="https://dunghvcs.github.io/media/posts/5//gallery/NF1-thumbnail.png" alt="" width="720" height="690"></a></figure><figure class="gallery__item"><a href="https://dunghvcs.github.io/media/posts/5//gallery/NF2.png" data-size="677x540"><img loading="lazy" src="https://dunghvcs.github.io/media/posts/5//gallery/NF2-thumbnail.png" alt="" width="677" height="540"></a></figure></div></div></div></article></main><footer class="footer"><div class="wrapper"><div class="footer__copyright"><p>Copyright@CVISLab</p></div><button id="backToTop" class="footer__bttop" aria-label="Back to top" title="Back to top"><svg width="20" height="20"><use xlink:href="https://dunghvcs.github.io/assets/svg/svg-map.svg#toparrow"/></svg></button></div></footer><script defer="defer" src="https://dunghvcs.github.io/assets/js/scripts.min.js?v=d0fc1030089a37f93a2d51bf6d07565c"></script><script>window.publiiThemeMenuConfig={mobileMenuMode:'sidebar',animationSpeed:300,submenuWidth: 'auto',doubleClickTime:500,mobileMenuExpandableSubmenus:true,relatedContainerForOverlayMenuSelector:'.top'};</script><script>var images = document.querySelectorAll('img[loading]');
        for (var i = 0; i < images.length; i++) {
            if (images[i].complete) {
                images[i].classList.add('is-loaded');
            } else {
                images[i].addEventListener('load', function () {
                    this.classList.add('is-loaded');
                }, false);
            }
        }</script></body></html>