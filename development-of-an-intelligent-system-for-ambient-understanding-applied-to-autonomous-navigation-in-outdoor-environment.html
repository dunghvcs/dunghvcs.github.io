<!DOCTYPE html><html lang="en-gb"><head><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no"><title>[NAFOSTED] Project ambient understanding - dunghv.github.io</title><meta name="description" content="Development of an intelligent system for ambient understanding applied to autonomous navigation in outdoor environment.  This project proposes and studies a novel method that improves efficiency of scene understanding, which is useful for autonomous navigation, based on the multiple sensors-based. The method is expected to provide the better scene understanding, which then allows a robot to avoid obstacles in front of its navigation. The method consists of some stages. First, a path planning is investigated, which concerns about the findings of the efficient path to facilitate the autonomous driving. The second is referred to the problem of the motion estimation and the localization prediction of running vehicle. It is addressed based on applying the fusion of cameras, LRF and GPS devices. Our research proposes a new method that uses the minimal set of parameters consisting of the geometrical constraints for estimating the 3D motion of vehicle using cameras and LRF. The cumulative errors of visual odometry are excluded using the GPS-based correction relied on the maximum likelihood estimation in particle filter. The semantic of object classification and detection are also studied. The obstacle detection, place recognition techniques are used as a solution to assisting the autonomous driver. We focus on dealing with detecting obstacles that commonly occur such as pedestrians and vehicles. The place recognition is also considered for scene understanding and mapping. We introduce improving of feature descriptors, deformable part model as well hybrid boosting SVM and neural network. "><meta name="generator" content="Publii Open-Source CMS for Static Site"><link rel="canonical" href="https://dunghvcs.github.io/development-of-an-intelligent-system-for-ambient-understanding-applied-to-autonomous-navigation-in-outdoor-environment.html"><link rel="alternate" type="application/atom+xml" href="https://dunghvcs.github.io/feed.xml" title="dunghv.github.io - RSS"><link rel="alternate" type="application/json" href="https://dunghvcs.github.io/feed.json" title="dunghv.github.io - JSON"><meta property="og:title" content="[NAFOSTED] Project ambient understanding"><meta property="og:image" content="https://dunghvcs.github.io/media/website/CVISLab.png"><meta property="og:image:width" content="816"><meta property="og:image:height" content="328"><meta property="og:site_name" content="dunghv.github.io"><meta property="og:description" content="Development of an intelligent system for ambient understanding applied to autonomous navigation in outdoor environment.  This project proposes and studies a novel method that improves efficiency of scene understanding, which is useful for autonomous navigation, based on the multiple sensors-based. The method is expected to provide the better scene understanding, which then allows a robot to avoid obstacles in front of its navigation. The method consists of some stages. First, a path planning is investigated, which concerns about the findings of the efficient path to facilitate the autonomous driving. The second is referred to the problem of the motion estimation and the localization prediction of running vehicle. It is addressed based on applying the fusion of cameras, LRF and GPS devices. Our research proposes a new method that uses the minimal set of parameters consisting of the geometrical constraints for estimating the 3D motion of vehicle using cameras and LRF. The cumulative errors of visual odometry are excluded using the GPS-based correction relied on the maximum likelihood estimation in particle filter. The semantic of object classification and detection are also studied. The obstacle detection, place recognition techniques are used as a solution to assisting the autonomous driver. We focus on dealing with detecting obstacles that commonly occur such as pedestrians and vehicles. The place recognition is also considered for scene understanding and mapping. We introduce improving of feature descriptors, deformable part model as well hybrid boosting SVM and neural network. "><meta property="og:url" content="https://dunghvcs.github.io/development-of-an-intelligent-system-for-ambient-understanding-applied-to-autonomous-navigation-in-outdoor-environment.html"><meta property="og:type" content="article"><link rel="stylesheet" href="https://dunghvcs.github.io/assets/css/fontawesome-all.min.css?v=85514f933f9e0b82460af63f1a403fa5"><link rel="stylesheet" href="https://dunghvcs.github.io/assets/css/style.css?v=4d806e68f114f2f853df749737f83210"><script type="application/ld+json">{"@context":"http://schema.org","@type":"Article","mainEntityOfPage":{"@type":"WebPage","@id":"https://dunghvcs.github.io/development-of-an-intelligent-system-for-ambient-understanding-applied-to-autonomous-navigation-in-outdoor-environment.html"},"headline":"[NAFOSTED] Project ambient understanding","datePublished":"2026-02-13T10:18+07:00","dateModified":"2026-02-13T10:22+07:00","image":{"@type":"ImageObject","url":"https://dunghvcs.github.io/media/website/CVISLab.png","height":328,"width":816},"description":"Development of an intelligent system for ambient understanding applied to autonomous navigation in outdoor environment.  This project proposes and studies a novel method that improves efficiency of scene understanding, which is useful for autonomous navigation, based on the multiple sensors-based. The method is expected to provide the better scene understanding, which then allows a robot to avoid obstacles in front of its navigation. The method consists of some stages. First, a path planning is investigated, which concerns about the findings of the efficient path to facilitate the autonomous driving. The second is referred to the problem of the motion estimation and the localization prediction of running vehicle. It is addressed based on applying the fusion of cameras, LRF and GPS devices. Our research proposes a new method that uses the minimal set of parameters consisting of the geometrical constraints for estimating the 3D motion of vehicle using cameras and LRF. The cumulative errors of visual odometry are excluded using the GPS-based correction relied on the maximum likelihood estimation in particle filter. The semantic of object classification and detection are also studied. The obstacle detection, place recognition techniques are used as a solution to assisting the autonomous driver. We focus on dealing with detecting obstacles that commonly occur such as pedestrians and vehicles. The place recognition is also considered for scene understanding and mapping. We introduce improving of feature descriptors, deformable part model as well hybrid boosting SVM and neural network. ","author":{"@type":"Person","name":"Van-Dung Hoang","url":"https://dunghvcs.github.io/authors/van-dung-hoang/"},"publisher":{"@type":"Organization","name":"Van-Dung Hoang","logo":{"@type":"ImageObject","url":"https://dunghvcs.github.io/media/website/CVISLab.png","height":328,"width":816}}}</script><noscript><style>img[loading] {
                    opacity: 1;
                }</style></noscript></head><body class="is-preload post-template"><div id="wrapper"><div id="main"><div class="inner"><header id="header"><a class="logo logo-image" href="https://dunghvcs.github.io/"><img src="https://dunghvcs.github.io/media/website/CVISLab.png" alt="dunghv.github.io" width="816" height="328"></a></header><article class="post"><header class="main post__header"><h1>[NAFOSTED] Project ambient understanding</h1></header><div class="post__inner post__entry"><h2><span style="color: #169179;"><strong><span style="color: #169179;">Development of an intelligent system for ambient understanding applied to autonomous navigation in outdoor environment.</span>  </strong></span></h2><p>This project proposes and studies a novel method that improves efficiency of scene understanding, which is useful for autonomous navigation, based on the multiple sensors-based. The method is expected to provide the better scene understanding, which then allows a robot to avoid obstacles in front of its navigation. The method consists of some stages. First, a path planning is investigated, which concerns about the findings of the efficient path to facilitate the autonomous driving. The second is referred to the problem of the motion estimation and the localization prediction of running vehicle. It is addressed based on applying the fusion of cameras, LRF and GPS devices. Our research proposes a new method that uses the minimal set of parameters consisting of the geometrical constraints for estimating the 3D motion of vehicle using cameras and LRF. The cumulative errors of visual odometry are excluded using the GPS-based correction relied on the maximum likelihood estimation in particle filter. The semantic of object classification and detection are also studied. The obstacle detection, place recognition techniques are used as a solution to assisting the autonomous driver. We focus on dealing with detecting obstacles that commonly occur such as pedestrians and vehicles. The place recognition is also considered for scene understanding and mapping. We introduce improving of feature descriptors, deformable part model as well hybrid boosting SVM and neural network. </p><div class="gallery-wrapper"><div class="gallery" data-is-empty="false" data-translation="Add images" data-columns="3"><figure class="gallery__item"><a href="https://dunghvcs.github.io/media/posts/5//gallery/NF1.png" data-size="956x916"><img loading="lazy" src="https://dunghvcs.github.io/media/posts/5//gallery/NF1-thumbnail.png" alt="" width="720" height="690"></a></figure><figure class="gallery__item"><a href="https://dunghvcs.github.io/media/posts/5//gallery/NF2.png" data-size="677x540"><img loading="lazy" src="https://dunghvcs.github.io/media/posts/5//gallery/NF2-thumbnail.png" alt="" width="677" height="540"></a></figure></div></div></div><footer class="post__inner post__footer"><div class="post__share"><h3>Share post:</h3></div></footer></article></div></div><div id="sidebar"><div class="inner"><div id="search" class="alt"></div><nav id="menu"><header class="major"><h2>Menu</h2></header><ul><li><a href="https://dunghvcs.github.io/" target="_self">Home</a></li><li><a href="https://dunghvcs.github.io/aciids2017-kanazawa-japan.html" target="_self">News</a></li><li class="active"><a href="https://dunghvcs.github.io/development-of-an-intelligent-system-for-ambient-understanding-applied-to-autonomous-navigation-in-outdoor-environment.html" target="_self">Research</a></li><li><a href="https://dunghvcs.github.io/publications.html" target="_self">Publications</a></li></ul></nav><section><header class="major"><h2>Get in touch</h2></header><p>Faculty of Information Technology<br>HCMC University of Technology and Engineering<br>Add: 01 Vo Van Ngan, Thu Duc, Ho Chi Minh city, Viet Nam<br>Email: dunghv@hcmute.edu.vn</p></section><footer id="footer"><p><span style="color: #ba372a;"><strong>@CVISLab</strong>-</span> Computer Vision &amp; Intelligent Systems Laboratory</p></footer></div></div></div><script src="https://dunghvcs.github.io/assets/js/jquery.min.js?v=7c14a783dfeb3d238ccd3edd840d82ee"></script><script src="https://dunghvcs.github.io/assets/js/browser.min.js?v=c07298dd19048a8a69ad97e754dfe8d0"></script><script src="https://dunghvcs.github.io/assets/js/breakpoints.min.js?v=81a479eb099e3b187613943b085923b8"></script><script src="https://dunghvcs.github.io/assets/js/util.min.js?v=cbdaf7c20ac2883c77ae23acfbabd47e"></script><script src="https://dunghvcs.github.io/assets/js/main.min.js?v=08add7f6d435054ad38ec38d7cf8be40"></script><script>var images=document.querySelectorAll("img[loading]");for(var i=0;i<images.length;i++){if(images[i].complete){images[i].classList.add("is-loaded")}else{images[i].addEventListener("load",function(){this.classList.add("is-loaded")},false)}};</script></body></html>