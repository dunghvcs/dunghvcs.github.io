<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <title>dunghv.github.io</title>
    <link href="https://dunghvcs.github.io/feed.xml" rel="self" />
    <link href="https://dunghvcs.github.io" />
    <updated>2026-02-14T10:44:56+07:00</updated>
    <author>
        <name>Van-Dung Hoang</name>
    </author>
    <id>https://dunghvcs.github.io</id>

    <entry>
        <title>[NAFOSTED] Project 2023: Deep learning &amp; Feature extraction</title>
        <author>
            <name>Van-Dung Hoang</name>
        </author>
        <link href="https://dunghvcs.github.io/nafosted-project-2023.html"/>
        <id>https://dunghvcs.github.io/nafosted-project-2023.html</id>
            <category term="Researches"/>

        <updated>2026-02-14T10:30:03+07:00</updated>
            <summary type="html">
                <![CDATA[
                    Improvement of deep learning and feature extraction methods for enhancing performance of pattern recognition systems was funded by the National Foundation-NAFOSTED Today with the fast-growing of artificial intelligence (AI), intelligence systems have been strongly studied and developed accomplished outstanding results, such as in the areas of robotics, intelligent assistance systems,&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                <p class="CjVfdc"><span style="color: #169179;"><span class="C9DxTc ">Improvement of deep learning and feature extraction methods for enhancing performance of pattern recognition systems was f</span><small id="h.mn4r8wg5orsm" class="zfr3Q TMjjoe CDt4Ke " dir="ltr"><span class="C9DxTc ">unded by the National Foundation-N</span><span class="C9DxTc ">AFOSTED</span></small></span></p>
<div>
<p class="zfr3Q CDt4Ke " dir="ltr"><span class="C9DxTc ">Today with the fast-growing of artificial intelligence (AI), intelligence systems have been strongly studied and developed accomplished outstanding results, such as in the areas of robotics, intelligent assistance systems, medical image-based disease diagnosis, and so on. Developed machine learning methods for increasingly feature extraction, optimal model in terms of accuracy, processing speed have become a major research trend. Some research orientations in this subdomain include developing solutions to optimize deep learning models and learning hyperparameters for high discriminated feature extraction and outperformed pattern recognition. This project concentrates on studying and proposing novel approaches in machine learning techniques and feature extraction from images. The methods are designed to provide better pattern recognition in real datasets. Resulted solutions support intelligent decisions and suggestions such as recognizing diseases using visual data in medical diagnosis, detecting abnormal objects or dangerous behaviors in surveillance systems. We expect this research to be completed and contributed to the trend machine learning solutions that facilitate implementing and operating intelligent systems on resource-limited hardware to solve difficult data problems for the classification and recognition of complex objects and events. The result is toward AI technologies into practice application with acceptable costs.</span></p>
<p class="zfr3Q CDt4Ke " dir="ltr"><span class="C9DxTc ">Develop AI technology based on deep learning models for feature extraction and pattern recognition to solve specific problems in computer vision such as image classification, object detection, medical image processing, action recognition, and scene understanding for surveillance systems.¬†</span></p>
<figure class="post__image"><img loading="lazy"  src="https://dunghvcs.github.io/media/posts/18/NF2.png" alt="" width="677" height="540" sizes="(max-width: 1920px) 100vw, 1920px" srcset="https://dunghvcs.github.io/media/posts/18/responsive/NF2-xs.png 640w ,https://dunghvcs.github.io/media/posts/18/responsive/NF2-sm.png 768w ,https://dunghvcs.github.io/media/posts/18/responsive/NF2-md.png 1024w ,https://dunghvcs.github.io/media/posts/18/responsive/NF2-lg.png 1366w ,https://dunghvcs.github.io/media/posts/18/responsive/NF2-xl.png 1600w ,https://dunghvcs.github.io/media/posts/18/responsive/NF2-2xl.png 1920w"></figure>
</div>
<h3 id="h.kujl4eg0r5ll_l" class="zfr3Q OmQG5e CDt4Ke " dir="ltr"></h3>
            ]]>
        </content>
    </entry>
    <entry>
        <title>Project 2019- Melanoma Image Prediction</title>
        <author>
            <name>Van-Dung Hoang</name>
        </author>
        <link href="https://dunghvcs.github.io/project-2019-melanoma-image-prediction.html"/>
        <id>https://dunghvcs.github.io/project-2019-melanoma-image-prediction.html</id>
        <media:content url="https://dunghvcs.github.io/media/posts/17/Detai_CS2018_2.png" medium="image" />
            <category term="Researches"/>

        <updated>2026-02-14T10:24:27+07:00</updated>
            <summary type="html">
                <![CDATA[
                        <img src="https://dunghvcs.github.io/media/posts/17/Detai_CS2018_2.png" alt="" />
                    Research on Deep Neural Network Techniques for Melanoma Image Prediction: Study image analysis and processing techniques, as well as artificial intelligence methods, particularly those based on large-scale data representation and deep learning approaches. Propose solutions that apply artificial intelligence techniques to image analysis and processing, specifically for image segmentation and&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                    <p><img src="https://dunghvcs.github.io/media/posts/17/Detai_CS2018_2.png" class="type:primaryImage" alt="" /></p>
                <p><strong>Research on Deep Neural Network Techniques for Melanoma Image Prediction:</strong></p>
<ul>
<li data-start="0" data-end="185">
<p data-start="2" data-end="185">Study image analysis and processing techniques, as well as artificial intelligence methods, particularly those based on large-scale data representation and deep learning approaches.</p>
</li>
<li data-start="186" data-end="346">
<p data-start="188" data-end="346">Propose solutions that apply artificial intelligence techniques to image analysis and processing, specifically for image segmentation and anomaly detection.</p>
</li>
<li data-start="347" data-end="410">
<p data-start="349" data-end="410">Collect and select image datasets related to skin melanoma.</p>
</li>
<li data-start="411" data-end="574">
<p data-start="413" data-end="574">Conduct experiments and evaluate image analysis and classification solutions for detecting pigmentation issues associated with melanoma, a type of skin cancer.</p>
</li>
<li data-start="575" data-end="681" data-is-last-node="">
<p data-start="577" data-end="681" data-is-last-node="">Collect data, prepare research papers, present at specialized conferences, and publish research results.</p>
</li>
</ul>
<figure class="post__image"><img loading="lazy"  src="https://dunghvcs.github.io/media/posts/17/Detai_CS2018_1.png" alt="" width="576" height="724" sizes="(max-width: 1920px) 100vw, 1920px" srcset="https://dunghvcs.github.io/media/posts/17/responsive/Detai_CS2018_1-xs.png 640w ,https://dunghvcs.github.io/media/posts/17/responsive/Detai_CS2018_1-sm.png 768w ,https://dunghvcs.github.io/media/posts/17/responsive/Detai_CS2018_1-md.png 1024w ,https://dunghvcs.github.io/media/posts/17/responsive/Detai_CS2018_1-lg.png 1366w ,https://dunghvcs.github.io/media/posts/17/responsive/Detai_CS2018_1-xl.png 1600w ,https://dunghvcs.github.io/media/posts/17/responsive/Detai_CS2018_1-2xl.png 1920w"></figure>
            ]]>
        </content>
    </entry>
    <entry>
        <title>Project2019-Virtual tour</title>
        <author>
            <name>Van-Dung Hoang</name>
        </author>
        <link href="https://dunghvcs.github.io/project2019-virtual-tour.html"/>
        <id>https://dunghvcs.github.io/project2019-virtual-tour.html</id>
        <media:content url="https://dunghvcs.github.io/media/posts/16/Tinh2-2.png" medium="image" />
            <category term="Researches"/>

        <updated>2026-02-14T10:15:14+07:00</updated>
            <summary type="html">
                <![CDATA[
                        <img src="https://dunghvcs.github.io/media/posts/16/Tinh2-2.png" alt="" />
                    Virtual tour development of famous places in Quang Binh using panoramic stitching, 3D interaction and modern web technology, which funded by the QB People's Committee. Collection of Tourist Site Information The research team conducted field surveys at 32 scenic and tourist destinations across Qu·∫£ng B√¨nh in accordance with the proposed&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                    <p><img src="https://dunghvcs.github.io/media/posts/16/Tinh2-2.png" class="type:primaryImage" alt="" /></p>
                <div class="CjVfdc CJIdie"><span class="C9DxTc ">Virtual tour development of famous places in Quang Binh using panoramic stitching, 3D interaction and modern web technology, which funded by the QB People's Committee.</span></div>
<div>
<p data-start="0" data-end="476"><strong data-start="0" data-end="49">Collection of Tourist Site Information</strong><br data-start="49" data-end="52">The research team conducted field surveys at 32 scenic and tourist destinations across <span class="hover:entity-accent entity-underline inline cursor-pointer align-baseline"><span class="whitespace-normal">Qu·∫£ng B√¨nh</span></span> in accordance with the proposed research objectives and collected relevant data. The collected information includes site names, tourism types, addresses, GPS locations, and basic descriptive characteristics, which serve as reference data for the subsequent process of image and dataset collection.</p>
<p data-start="478" data-end="974"><strong data-start="478" data-end="512">Data Collection¬†</strong><br data-start="512" data-end="515">The research team carried out surveys and gathered information and written materials for 32 scenic and tourist destinations in Qu·∫£ng B√¨nh province. The collected data include descriptive information about tourist sites, associated service systems, tourism promotional articles, the number of photographs taken at each site for panoramic image construction, and images used for album creation. All data were processed to ensure adequate quantity and quality.</p>
<p data-start="976" data-end="1247" data-is-last-node="" data-is-only-node=""><strong data-start="976" data-end="1017">Software System Design</strong><br data-start="1017" data-end="1020">The software system is designed to meet management requirements, provide information about tourist destinations, support virtual tourism experiences, display photo albums, present related services, and enable video integration.</p>
<figure class="post__image"><img loading="lazy"  src="https://dunghvcs.github.io/media/posts/16/Detai_tinh2019_1.png" alt="" width="842" height="760" sizes="(max-width: 1920px) 100vw, 1920px" srcset="https://dunghvcs.github.io/media/posts/16/responsive/Detai_tinh2019_1-xs.png 640w ,https://dunghvcs.github.io/media/posts/16/responsive/Detai_tinh2019_1-sm.png 768w ,https://dunghvcs.github.io/media/posts/16/responsive/Detai_tinh2019_1-md.png 1024w ,https://dunghvcs.github.io/media/posts/16/responsive/Detai_tinh2019_1-lg.png 1366w ,https://dunghvcs.github.io/media/posts/16/responsive/Detai_tinh2019_1-xl.png 1600w ,https://dunghvcs.github.io/media/posts/16/responsive/Detai_tinh2019_1-2xl.png 1920w"></figure>
<figure class="post__image"><img loading="lazy"  src="https://dunghvcs.github.io/media/posts/16/Detai_tinh2019_2.png" alt="" width="1168" height="774" sizes="(max-width: 1920px) 100vw, 1920px" srcset="https://dunghvcs.github.io/media/posts/16/responsive/Detai_tinh2019_2-xs.png 640w ,https://dunghvcs.github.io/media/posts/16/responsive/Detai_tinh2019_2-sm.png 768w ,https://dunghvcs.github.io/media/posts/16/responsive/Detai_tinh2019_2-md.png 1024w ,https://dunghvcs.github.io/media/posts/16/responsive/Detai_tinh2019_2-lg.png 1366w ,https://dunghvcs.github.io/media/posts/16/responsive/Detai_tinh2019_2-xl.png 1600w ,https://dunghvcs.github.io/media/posts/16/responsive/Detai_tinh2019_2-2xl.png 1920w"></figure>
<figure class="post__image"><img loading="lazy"  src="https://dunghvcs.github.io/media/posts/16/IMG-0366.JPG" alt="" width="1366" height="768" sizes="(max-width: 1920px) 100vw, 1920px" srcset="https://dunghvcs.github.io/media/posts/16/responsive/IMG-0366-xs.JPG 640w ,https://dunghvcs.github.io/media/posts/16/responsive/IMG-0366-sm.JPG 768w ,https://dunghvcs.github.io/media/posts/16/responsive/IMG-0366-md.JPG 1024w ,https://dunghvcs.github.io/media/posts/16/responsive/IMG-0366-lg.JPG 1366w ,https://dunghvcs.github.io/media/posts/16/responsive/IMG-0366-xl.JPG 1600w ,https://dunghvcs.github.io/media/posts/16/responsive/IMG-0366-2xl.JPG 1920w"></figure>
</div>
<div>¬†</div>
<h3 id="h.fklu04cvv6wh_l" class="zfr3Q OmQG5e CDt4Ke " dir="ltr"></h3>
            ]]>
        </content>
    </entry>
    <entry>
        <title>Project 2015- Surveillance Systems</title>
        <author>
            <name>Van-Dung Hoang</name>
        </author>
        <link href="https://dunghvcs.github.io/project-2015-funded-by-the-qb-peoples-committee.html"/>
        <id>https://dunghvcs.github.io/project-2015-funded-by-the-qb-peoples-committee.html</id>
        <media:content url="https://dunghvcs.github.io/media/posts/15/IMG_2346.jpg" medium="image" />
            <category term="Researches"/>

        <updated>2026-02-14T10:02:05+07:00</updated>
            <summary type="html">
                <![CDATA[
                        <img src="https://dunghvcs.github.io/media/posts/15/IMG_2346.jpg" alt="" />
                    Proposal a computer vision- based surveillance system applied to secured to office building in Quang Binh province was funded by the QB People's Committee. General Objectives: To investigate and analyze the current state of technology applications in ensuring security for socio-economic development. To propose a real-time security recognition, tracking, and&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                    <p><img src="https://dunghvcs.github.io/media/posts/15/IMG_2346.jpg" class="type:primaryImage" alt="" /></p>
                <div class="CjVfdc"><span class="C9DxTc ">Proposal a computer vision- based surveillance system applied to secured to office building in Quang Binh province was funded by the QB People's Committee.</span></div>
<div>
<p data-start="0" data-end="25"><strong data-start="0" data-end="23">General Objectives:</strong></p>
<ul data-start="26" data-end="258">
<li data-start="26" data-end="154">
<p data-start="28" data-end="154">To investigate and analyze the current state of technology applications in ensuring security for socio-economic development.</p>
</li>
<li data-start="155" data-end="258">
<p data-start="157" data-end="258">To propose a real-time security recognition, tracking, and alert system model for office buildings.</p>
</li>
</ul>
<figure class="post__image"><img loading="lazy"  src="https://dunghvcs.github.io/media/posts/15/tinh1.png" alt="" width="1038" height="1086" sizes="(max-width: 1920px) 100vw, 1920px" srcset="https://dunghvcs.github.io/media/posts/15/responsive/tinh1-xs.png 640w ,https://dunghvcs.github.io/media/posts/15/responsive/tinh1-sm.png 768w ,https://dunghvcs.github.io/media/posts/15/responsive/tinh1-md.png 1024w ,https://dunghvcs.github.io/media/posts/15/responsive/tinh1-lg.png 1366w ,https://dunghvcs.github.io/media/posts/15/responsive/tinh1-xl.png 1600w ,https://dunghvcs.github.io/media/posts/15/responsive/tinh1-2xl.png 1920w"></figure>
<p data-start="260" data-end="286"><strong data-start="260" data-end="284">Specific Objectives:</strong></p>
<ul data-start="287" data-end="888">
<li data-start="287" data-end="334">
<p data-start="289" data-end="334">To retrieve data from surveillance cameras.</p>
</li>
<li data-start="335" data-end="699">
<p data-start="337" data-end="372">Recognition and tracking methods:</p>
<ul data-start="375" data-end="699">
<li data-start="375" data-end="424">
<p data-start="377" data-end="424">Propose image feature representation methods.</p>
</li>
<li data-start="427" data-end="491">
<p data-start="429" data-end="491">Propose models for target objects to be recognized (humans).</p>
</li>
<li data-start="494" data-end="568">
<p data-start="496" data-end="568">Propose artificial intelligence frameworks for training object models.</p>
</li>
<li data-start="571" data-end="639">
<p data-start="573" data-end="639">Propose and develop systems for object recognition and tracking.</p>
</li>
<li data-start="642" data-end="699">
<p data-start="644" data-end="699">Build datasets for training, evaluation, and testing.</p>
</li>
</ul>
</li>
<li data-start="701" data-end="839">
<p data-start="703" data-end="722"><strong data-start="703" data-end="720">Alert System:</strong></p>
<ul data-start="725" data-end="839">
<li data-start="725" data-end="781">
<p data-start="727" data-end="781">Analyze and develop semantic representation systems.</p>
</li>
<li data-start="784" data-end="839">
<p data-start="786" data-end="839">Build decision-support systems for security alerts.</p>
</li>
</ul>
</li>
<li data-start="841" data-end="888">
<p data-start="843" data-end="888">Conduct system experiments and evaluations.</p>
</li>
</ul>
<p data-start="890" data-end="919"><strong data-start="890" data-end="917">Research Subjects:</strong></p>
<ul data-start="920" data-end="1131" data-is-last-node="" data-is-only-node="">
<li data-start="920" data-end="984">
<p data-start="922" data-end="984">Suspicious individuals illegally entering office facilities.</p>
</li>
<li data-start="985" data-end="1059">
<p data-start="987" data-end="1059">Image processing, feature representation, and artificial intelligence.</p>
</li>
<li data-start="1060" data-end="1131" data-is-last-node="">
<p data-start="1062" data-end="1131" data-is-last-node="">Expert systems and contextual reasoning applied to security alerting.</p>
</li>
</ul>
<figure class="post__image"><img loading="lazy"  src="https://dunghvcs.github.io/media/posts/15/IMG_2418.jpg" alt="" width="2542" height="974" sizes="(max-width: 1920px) 100vw, 1920px" srcset="https://dunghvcs.github.io/media/posts/15/responsive/IMG_2418-xs.jpg 640w ,https://dunghvcs.github.io/media/posts/15/responsive/IMG_2418-sm.jpg 768w ,https://dunghvcs.github.io/media/posts/15/responsive/IMG_2418-md.jpg 1024w ,https://dunghvcs.github.io/media/posts/15/responsive/IMG_2418-lg.jpg 1366w ,https://dunghvcs.github.io/media/posts/15/responsive/IMG_2418-xl.jpg 1600w ,https://dunghvcs.github.io/media/posts/15/responsive/IMG_2418-2xl.jpg 1920w"></figure>
<figure class="post__image"><img loading="lazy"  src="https://dunghvcs.github.io/media/posts/15/IMG_2371.jpg" alt="" width="2592" height="1339" sizes="(max-width: 1920px) 100vw, 1920px" srcset="https://dunghvcs.github.io/media/posts/15/responsive/IMG_2371-xs.jpg 640w ,https://dunghvcs.github.io/media/posts/15/responsive/IMG_2371-sm.jpg 768w ,https://dunghvcs.github.io/media/posts/15/responsive/IMG_2371-md.jpg 1024w ,https://dunghvcs.github.io/media/posts/15/responsive/IMG_2371-lg.jpg 1366w ,https://dunghvcs.github.io/media/posts/15/responsive/IMG_2371-xl.jpg 1600w ,https://dunghvcs.github.io/media/posts/15/responsive/IMG_2371-2xl.jpg 1920w"></figure>
</div>
<h3 id="h.o4ldey3lih43_l" class="zfr3Q OmQG5e CDt4Ke " dir="ltr"></h3>
            ]]>
        </content>
    </entry>
    <entry>
        <title>Ulsan2023 - Visiting research</title>
        <author>
            <name>Van-Dung Hoang</name>
        </author>
        <link href="https://dunghvcs.github.io/ulsan2023-visiting-research.html"/>
        <id>https://dunghvcs.github.io/ulsan2023-visiting-research.html</id>
            <category term="Seminars"/>
            <category term="News"/>

        <updated>2026-02-14T09:56:24+07:00</updated>
            <summary type="html">
                <![CDATA[
                    Visiting research at¬†Ulsan ISLab¬†(Intelligent Systems Laboratory) in 2023, led by Professor Kang-Hyun Jo, focuses heavily on advanced computer vision applications, including generative models, 3D reconstruction, autonomous driving systems, and human motion/gait analysis. Key areas often involve 3D facial landmark detection and intelligent video systems.
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                <p>Visiting research at¬†<span data-wiz-uids="EvebVb_b" data-processed="true"><a jsuid="EvebVb_b" class="GI370e" data-ved="2ahUKEwiKr_u4_deSAxXbcPUHHZWdB98QgK4QegQIARAB" data-hveid="CAEQAQ" data-processed="true" href="https://www.google.com/search?q=Ulsan+ISLab&amp;sca_esv=4e4f828e227a99b7&amp;rlz=1C1YTUH_viVN1067VN1067&amp;biw=1920&amp;bih=911&amp;sxsrf=ANbL-n5v7v0nqWMcvqe6sEudzB43FR2XTg%3A1771037561148&amp;ei=eeOPaZrgCI7i2roPsLDa-QI&amp;ved=2ahUKEwiKr_u4_deSAxXbcPUHHZWdB98QgK4QegQIARAB&amp;uact=5&amp;oq=visiting+research+at+Ulsan+Islab+2023++on+Compuiter+vision+topic&amp;gs_lp=Egxnd3Mtd2l6LXNlcnAiQHZpc2l0aW5nIHJlc2VhcmNoIGF0IFVsc2FuIElzbGFiIDIwMjMgIG9uIENvbXB1aXRlciB2aXNpb24gdG9waWNIjrgBUNwHWMW2AXALeACQAQSYAd8BoAHfOqoBBjIuNTQuMbgBA8gBAPgBAZgCOaACvzDCAgoQABiwAxjWBBhHwgIFECEYoAHCAgYQABgWGB7CAgsQABiABBiGAxiKBcICBRAAGO8FwgIIEAAYgAQYogTCAgQQIxgnwgIIEAAYFhgKGB7CAgsQABiABBiRAhiKBcICBRAAGIAEwgIHECEYoAEYCsICBBAhGBXCAgQQIRgKwgIGECEYFRgKmAMAiAYBkAYIkgcFMTIuNDWgB_X7AbIHBDEuNDW4B5AwwgcJMy4zNS4xOC4xyAebAYAIAA&amp;sclient=gws-wiz-serp">Ulsan ISLab</a></span>¬†(Intelligent Systems Laboratory) in 2023, led by Professor Kang-Hyun Jo, focuses heavily on advanced computer vision applications, including generative models, 3D reconstruction, autonomous driving systems, and human motion/gait analysis. Key areas often involve 3D facial landmark detection and intelligent video systems.<span class="uJ19be notranslate" data-wiz-uids="EvebVb_d,EvebVb_e" data-processed="true"><span class="vKEkVd" data-animation-atomic="" data-wiz-attrbind="class=EvebVb_c/TKHnVd" data-processed="true"><span aria-hidden="true" data-processed="true">¬†</span></span></span></p>
<ul class="KsbFXc U6u95" data-processed="true">
<li data-hveid="CAMQAA" data-processed="true"><span class="T286Pc" data-sfc-cp="" data-processed="true"><strong class="Yjhzub" data-processed="true">3D Vision and Reconstruction:</strong>¬†Techniques for scene modeling and 3D pose estimation.</span></li>
<li data-hveid="CAMQAQ" data-processed="true"><span class="T286Pc" data-sfc-cp="" data-processed="true"><strong class="Yjhzub" data-processed="true">Intelligent Transportation/Driving:</strong>¬†Computer vision algorithms for autonomous vehicles and event detection.</span></li>
<li data-hveid="CAMQAg" data-processed="true"><span class="T286Pc" data-sfc-cp="" data-processed="true"><strong class="Yjhzub" data-processed="true">Computer Vision &amp; AI:</strong>¬†Deep learning techniques for image understanding, object detection, and tracking.</span></li>
<li data-hveid="CAMQAw" data-processed="true"><span class="T286Pc" data-sfc-cp="" data-processed="true"><strong class="Yjhzub" data-processed="true">Human Motion Analysis:</strong>¬†Analyzing gait and human movement for recognition task</span></li>
</ul>
<p>¬†</p>
<figure class="post__image"><img loading="lazy"  src="https://dunghvcs.github.io/media/posts/14/Ulsan20231_2.jpg" alt="" width="2560" height="1152" sizes="(max-width: 1920px) 100vw, 1920px" srcset="https://dunghvcs.github.io/media/posts/14/responsive/Ulsan20231_2-xs.jpg 640w ,https://dunghvcs.github.io/media/posts/14/responsive/Ulsan20231_2-sm.jpg 768w ,https://dunghvcs.github.io/media/posts/14/responsive/Ulsan20231_2-md.jpg 1024w ,https://dunghvcs.github.io/media/posts/14/responsive/Ulsan20231_2-lg.jpg 1366w ,https://dunghvcs.github.io/media/posts/14/responsive/Ulsan20231_2-xl.jpg 1600w ,https://dunghvcs.github.io/media/posts/14/responsive/Ulsan20231_2-2xl.jpg 1920w"></figure>
<figure class="post__image"><img loading="lazy"  src="https://dunghvcs.github.io/media/posts/14/Ulsan20231_1-2.JPG" alt="" width="4032" height="3024" sizes="(max-width: 1920px) 100vw, 1920px" srcset="https://dunghvcs.github.io/media/posts/14/responsive/Ulsan20231_1-2-xs.JPG 640w ,https://dunghvcs.github.io/media/posts/14/responsive/Ulsan20231_1-2-sm.JPG 768w ,https://dunghvcs.github.io/media/posts/14/responsive/Ulsan20231_1-2-md.JPG 1024w ,https://dunghvcs.github.io/media/posts/14/responsive/Ulsan20231_1-2-lg.JPG 1366w ,https://dunghvcs.github.io/media/posts/14/responsive/Ulsan20231_1-2-xl.JPG 1600w ,https://dunghvcs.github.io/media/posts/14/responsive/Ulsan20231_1-2-2xl.JPG 1920w"></figure>
            ]]>
        </content>
    </entry>
    <entry>
        <title>ACIIDS2023</title>
        <author>
            <name>Van-Dung Hoang</name>
        </author>
        <link href="https://dunghvcs.github.io/aciids2023.html"/>
        <id>https://dunghvcs.github.io/aciids2023.html</id>
            <category term="Conference Events"/>

        <updated>2026-02-14T09:52:08+07:00</updated>
            <summary type="html">
                <![CDATA[
                    ACIIDS 2023 is an international scientific conference for research in the field of intelligent information and database systems, held from 24 to 26 of July 2023 in Phuket, Thailand. The conference aims to provide an internationally respected forum for scientific research in intelligent information and database systems technologies and applications.
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                <p>ACIIDS 2023 is an international scientific conference for research in the field of intelligent information and database systems, held from 24 to 26 of July 2023 in Phuket, Thailand.</p>
<p>The conference aims to provide an internationally respected forum for scientific research in intelligent information and database systems technologies and applications. ACIIDS conference is ranked category B in the prestigious¬†<a href="http://portal.core.edu.au/conf-ranks/2188/">CORE ranking</a>.</p>
<p>The conference is hosted by King Mongkut‚Äôs Institute of Technology Ladkrabang, Thailand, and jointly organized by Wroc≈Çaw University of Science and Technology, Poland, in cooperation with IEEE SMC Technical Committee on Computational Collective Intelligence, European Research Center for Information Systems (ERCIS), University of Newcastle (Australia), Yeungnam University (Korea), International University - Vietnam National University HCMC (Vietnam), Leiden University (The Netherlands), Universiti Teknologi Malaysia (Malaysia), Ton Duc Thang University (Vietnam), BINUS University (Indonesia), and Vietnam National University, Hanoi (Vietnam).</p>
<p>The proceedings of ACIIDS 2023 will be published by Springer.</p>
<p class="zfr3Q CDt4Ke " dir="ltr"><span class="C9DxTc ">CVISLab member presents a contribution on "Combination of Deep Learning and Ambiguity Rejection for Improving Image-Based Disease Diagnosis".</span></p>
<p class="zfr3Q CDt4Ke " dir="ltr"><span class="C9DxTc ">A leader of CVISLab achieves outstanding contribution award for 15 Years of ACIIDS conference</span></p>
<p class="zfr3Q CDt4Ke " dir="ltr"><span class="C9DxTc ">Over all, everything is well organized.</span></p>
<figure class="post__image"><img loading="lazy"  src="https://dunghvcs.github.io/media/posts/13/ACIIDS2023_2.jpg" alt="" width="1280" height="1818" sizes="(max-width: 1920px) 100vw, 1920px" srcset="https://dunghvcs.github.io/media/posts/13/responsive/ACIIDS2023_2-xs.jpg 640w ,https://dunghvcs.github.io/media/posts/13/responsive/ACIIDS2023_2-sm.jpg 768w ,https://dunghvcs.github.io/media/posts/13/responsive/ACIIDS2023_2-md.jpg 1024w ,https://dunghvcs.github.io/media/posts/13/responsive/ACIIDS2023_2-lg.jpg 1366w ,https://dunghvcs.github.io/media/posts/13/responsive/ACIIDS2023_2-xl.jpg 1600w ,https://dunghvcs.github.io/media/posts/13/responsive/ACIIDS2023_2-2xl.jpg 1920w"></figure>
<figure class="post__image"><img loading="lazy"  src="https://dunghvcs.github.io/media/posts/13/ACIIDS2023_1.jpg" alt="" width="959" height="539" sizes="(max-width: 1920px) 100vw, 1920px" srcset="https://dunghvcs.github.io/media/posts/13/responsive/ACIIDS2023_1-xs.jpg 640w ,https://dunghvcs.github.io/media/posts/13/responsive/ACIIDS2023_1-sm.jpg 768w ,https://dunghvcs.github.io/media/posts/13/responsive/ACIIDS2023_1-md.jpg 1024w ,https://dunghvcs.github.io/media/posts/13/responsive/ACIIDS2023_1-lg.jpg 1366w ,https://dunghvcs.github.io/media/posts/13/responsive/ACIIDS2023_1-xl.jpg 1600w ,https://dunghvcs.github.io/media/posts/13/responsive/ACIIDS2023_1-2xl.jpg 1920w"></figure>
            ]]>
        </content>
    </entry>
    <entry>
        <title>ICSSE 2023</title>
        <author>
            <name>Van-Dung Hoang</name>
        </author>
        <link href="https://dunghvcs.github.io/icsse-2023.html"/>
        <id>https://dunghvcs.github.io/icsse-2023.html</id>
            <category term="Conference Events"/>

        <updated>2026-02-14T09:49:20+07:00</updated>
            <summary type="html">
                <![CDATA[
                    ICSSE 2023:¬†The Annual International Conference on System Science and Engineering, well known as ICSSE, is a reputational conference on System Science and Engineering area. ICSSE 2023, hosted by Ho Chi Minh City University of Technology and Education (Vietnam), Taiwan Association of System Science and Engineering (TASSE), National Taiwan Ocean University&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                <p class="zfr3Q CDt4Ke " dir="ltr"><span class="C9DxTc "><span style="color: #e03e2d;"><strong><span style="color: #2dc26b;">ICSSE 2023:</span>¬†</strong></span></span>The Annual International Conference on System Science and Engineering, well known as ICSSE, is a reputational conference on System Science and Engineering area.¬† ICSSE 2023, hosted by Ho Chi Minh City University of Technology and Education (Vietnam), Taiwan Association of System Science and Engineering (TASSE), National Taiwan Ocean University (Taiwan) and Rajamangala University of Technology Lanna (Thailand), will take place in Ho Chi Minh City, Vietnam during July 27-28, 2023.¬† The scholars, experts, engineers, and practitioners from all over the world are warmly invited to present the latest enhancements and innovations in the field of system science and engineering, as well as to facilitate interactions between scholars and practitioners. ICSSE 2023 will feature plenary speeches in emerging technology topics given by world renowned scholars. The conference welcomes all submissions of original research papers in all aspects of System Science and Engineering as listed below. The papers will go through a thorough and strict peer-review process in IEEE standards.</p>
<p dir="ltr">System Science and Engineering is a research area that covers a wide spectrum of modern technologies. A system includes a collection of entities and their interrelationships to jointly form a whole greater than the sum of the entities. It also involves human, organizations, cultures, activities and interrelationships. Nowadays, systems composed of autonomous subsystems are more and more widely used and show the great advantages of expanded data density, connectivity, and ubiquitous computational resources with higher interdependence and interaction complexity. This has in turn made the job of planning, developing and deploying complex systems even more difficult and intelligent.</p>
<p class="zfr3Q CDt4Ke " dir="ltr"><span class="C9DxTc ">CVISLab member presents a contribution on "</span><span class="C9DxTc ">Fusion of ViT Technique and Image Filtering in Deep Learning for Plant Pests and Diseases Recognition</span><span class="C9DxTc ">".</span></p>
<p class="zfr3Q CDt4Ke " dir="ltr"><span class="C9DxTc ">Over all, everything is well organized.</span></p>
<figure class="post__image"><img loading="lazy"  src="https://dunghvcs.github.io/media/posts/12/ICSSE2023_1.JPG" alt="" width="1280" height="798" sizes="(max-width: 1920px) 100vw, 1920px" srcset="https://dunghvcs.github.io/media/posts/12/responsive/ICSSE2023_1-xs.JPG 640w ,https://dunghvcs.github.io/media/posts/12/responsive/ICSSE2023_1-sm.JPG 768w ,https://dunghvcs.github.io/media/posts/12/responsive/ICSSE2023_1-md.JPG 1024w ,https://dunghvcs.github.io/media/posts/12/responsive/ICSSE2023_1-lg.JPG 1366w ,https://dunghvcs.github.io/media/posts/12/responsive/ICSSE2023_1-xl.JPG 1600w ,https://dunghvcs.github.io/media/posts/12/responsive/ICSSE2023_1-2xl.JPG 1920w"></figure>
<figure class="post__image"><img loading="lazy"  src="https://dunghvcs.github.io/media/posts/12/ICSSE2023_2.JPG" alt="" width="960" height="721" sizes="(max-width: 1920px) 100vw, 1920px" srcset="https://dunghvcs.github.io/media/posts/12/responsive/ICSSE2023_2-xs.JPG 640w ,https://dunghvcs.github.io/media/posts/12/responsive/ICSSE2023_2-sm.JPG 768w ,https://dunghvcs.github.io/media/posts/12/responsive/ICSSE2023_2-md.JPG 1024w ,https://dunghvcs.github.io/media/posts/12/responsive/ICSSE2023_2-lg.JPG 1366w ,https://dunghvcs.github.io/media/posts/12/responsive/ICSSE2023_2-xl.JPG 1600w ,https://dunghvcs.github.io/media/posts/12/responsive/ICSSE2023_2-2xl.JPG 1920w"></figure>
            ]]>
        </content>
    </entry>
    <entry>
        <title>FAIR 2023</title>
        <author>
            <name>Van-Dung Hoang</name>
        </author>
        <link href="https://dunghvcs.github.io/fair-2023.html"/>
        <id>https://dunghvcs.github.io/fair-2023.html</id>
        <media:content url="https://dunghvcs.github.io/media/posts/11/FAIR2023_2.jpg" medium="image" />
            <category term="Conference Events"/>

        <updated>2026-02-14T09:34:04+07:00</updated>
            <summary type="html">
                <![CDATA[
                        <img src="https://dunghvcs.github.io/media/posts/11/FAIR2023_2.jpg" alt="" />
                    FAIR - Fundamental and Applied Information Technology Li√™n hi·ªáp c√°c H·ªôi Khoa h·ªçc v√† K·ªπ thu·∫≠t Vi·ªát Nam, Vi·ªán H√†n l√¢m Khoa h·ªçc v√† C√¥ng ngh·ªá Vi·ªát Nam ph·ªëi h·ª£p c√πng¬†Tr∆∞·ªùng ƒê·∫°i h·ªçc C√¥ng nghi·ªáp H√† N·ªôi¬†v√† c√°c c∆° quan khoa h·ªçc, c√°c nh√† khoa h·ªçc t·ª´ c√°c vi·ªán nghi√™n&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                    <p><img src="https://dunghvcs.github.io/media/posts/11/FAIR2023_2.jpg" class="type:primaryImage" alt="" /></p>
                <p class="zfr3Q CDt4Ke " dir="ltr"><span style="color: #169179;"><strong><span class="C9DxTc ">FAIR - Fundamental and Applied Information Technology</span><span class="C9DxTc ">¬†</span></strong></span></p>
<p>Li√™n hi·ªáp c√°c H·ªôi Khoa h·ªçc v√† K·ªπ thu·∫≠t Vi·ªát Nam, Vi·ªán H√†n l√¢m Khoa h·ªçc v√† C√¥ng ngh·ªá Vi·ªát Nam ph·ªëi h·ª£p c√πng¬†<span class="fontstyle0">Tr∆∞·ªùng ƒê·∫°i h·ªçc C√¥ng nghi·ªáp H√† N·ªôi¬†</span>v√† c√°c c∆° quan khoa h·ªçc, c√°c nh√† khoa h·ªçc t·ª´ c√°c vi·ªán nghi√™n c·ª©u, c√°c tr∆∞·ªùng ƒë·∫°i h·ªçc ƒë·ªÉ t·ªï ch·ª©c H·ªôi ngh·ªã khoa h·ªçc qu·ªëc gia l·∫ßn th·ª© XVIII v·ªÅ "Nghi√™n c·ª©u c∆° b·∫£n v√† ·ª©ng d·ª•ng C√¥ng ngh·ªá th√¥ng tin".</p>
<p dir="ltr">Ch·ªß ƒë·ªÅ ch√≠nh c·ªßa H·ªôi ngh·ªã l√† "¬†<span class="fontstyle0">Chuy·ªÉn ƒë·ªïi s·ªë v√† c√°c xu th·∫ø t∆∞∆°ng lai</span>". Tuy nhi√™n, do truy·ªÅn th·ªëng c·ªßa H·ªôi ngh·ªã n√™n kh√¥ng h·∫°n ch·∫ø v·ªÅ n·ªôi dung. H·ªôi ngh·ªã nƒÉm nay ƒë∆∞·ª£c s·ª± b·∫£o tr·ª£ chuy√™n m√¥n c·ªßa 4 c∆° s·ªü ƒë√†o t·∫°o uy t√≠n trong lƒ©nh v·ª±c c√¥ng ngh·ªá th√¥ng tin ‚Äì truy·ªÅn th√¥ng l√† ƒê·∫°i h·ªçc ƒê√† N·∫µng, H·ªçc vi·ªán C√¥ng ngh·ªá B∆∞u ch√≠nh Vi·ªÖn th√¥ng, Tr∆∞·ªùng ƒê·∫°i hoc C√¥ng ngh·ªá Th√¥ng tin &amp; Truy·ªÅn th√¥ng Th√°i Nguy√™n, Vi·ªán C√¥ng ngh·ªá Th√¥ng tin ‚Äì ƒêHQGHN.<br>FAIR l·∫ßn th·ª© XVIII (FAIR'2025), t·ªï ch·ª©c t·∫°i Tr∆∞·ªùng ƒê·∫°i h·ªçc C√¥ng nghi·ªáp H√† N·ªôi v√†o 2 ng√†y: Th·ª© NƒÉm v√† Th·ª© S√°u, 21 - 22/08/2025.</p>
<div class="gallery-wrapper"><div class="gallery" data-is-empty="false" data-translation="Add images" data-columns="3">
<figure class="gallery__item"><a href="https://dunghvcs.github.io/media/posts/11/gallery/FAIR2023_1.jpg" data-size="1163x960"><img loading="lazy" src="https://dunghvcs.github.io/media/posts/11/gallery/FAIR2023_1-thumbnail.jpg" alt="" width="720" height="594"></a></figure>
<figure class="gallery__item"><a href="https://dunghvcs.github.io/media/posts/11/gallery/FAIR2023_2.jpg" data-size="917x515"><img loading="lazy" src="https://dunghvcs.github.io/media/posts/11/gallery/FAIR2023_2-thumbnail.jpg" alt="" width="720" height="404"></a></figure>
</div></div>
<p class="zfr3Q CDt4Ke " dir="ltr"><span class="C9DxTc ">CVISLab member presents a contribution on "Performance Evaluation of Mediapipe and Openpose for Skeleton Data Extraction"</span></p>
<p class="zfr3Q CDt4Ke " dir="ltr"><span class="C9DxTc ">In this study, our focus lies in evaluating two approaches for extracting skeletal data based on OpenPose and Mediapipe frameworks across the KTH and UTD-MHAD datasets. The skeletal data extracted from both methods serves as input for the AcTv2 model, an enhanced version of the AcT model. Through training and evaluating on the AcTv2 model, we ascertain the effectiveness of both skeletal data extraction methods on specific datasets. The experimental results of this research contribute to a better understanding of the efficacy of these skeletal data extraction methods in providing informative data for the AcTv2 model to recognize human actions across different datasets.</span></p>
            ]]>
        </content>
    </entry>
    <entry>
        <title>Digital Image Processing</title>
        <author>
            <name>Van-Dung Hoang</name>
        </author>
        <link href="https://dunghvcs.github.io/digital-image-processing.html"/>
        <id>https://dunghvcs.github.io/digital-image-processing.html</id>
            <category term="Courses"/>

        <updated>2026-02-13T11:56:48+07:00</updated>
            <summary type="html">
                <![CDATA[
                    Digital Image Processing: Chapter 1: Introduction to image processing Chapter 2: Image enhancement in space domain Chapter 3: Image enhancement in frequency domain Chapter 4: Morphological image processing Chapter 5: Image segmentation Chapter 6: Feature extraction Chapter 7: Pattern recognition
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                <div class="CjVfdc">Digital Image Processing:<br>
<p>Chapter 1: Introduction to image processing</p>
<p>Chapter 2: Image enhancement in space domain</p>
<p>Chapter 3: Image enhancement in frequency domain</p>
<p>Chapter 4: Morphological image processing</p>
<p>Chapter 5: Image segmentation</p>
<p>Chapter 6: Feature extraction</p>
<p>Chapter 7: Pattern recognition</p>
</div>
<div><figure class="post__image"><img loading="lazy"  src="https://dunghvcs.github.io/media/posts/8/DIP1-2.png" alt="" width="813" height="594" sizes="(max-width: 1920px) 100vw, 1920px" srcset="https://dunghvcs.github.io/media/posts/8/responsive/DIP1-2-xs.png 640w ,https://dunghvcs.github.io/media/posts/8/responsive/DIP1-2-sm.png 768w ,https://dunghvcs.github.io/media/posts/8/responsive/DIP1-2-md.png 1024w ,https://dunghvcs.github.io/media/posts/8/responsive/DIP1-2-lg.png 1366w ,https://dunghvcs.github.io/media/posts/8/responsive/DIP1-2-xl.png 1600w ,https://dunghvcs.github.io/media/posts/8/responsive/DIP1-2-2xl.png 1920w"></figure></div>
<div>
<p>¬†</p>
</div>
<h3 id="h.i1ci6wnis21l_l" class="CDt4Ke zfr3Q OmQG5e" dir="ltr" tabindex="-1"></h3>
            ]]>
        </content>
    </entry>
    <entry>
        <title>2025 Year End Seminar¬†</title>
        <author>
            <name>Van-Dung Hoang</name>
        </author>
        <link href="https://dunghvcs.github.io/year-end-seminar.html"/>
        <id>https://dunghvcs.github.io/year-end-seminar.html</id>
            <category term="Seminars"/>

        <updated>2026-02-13T11:54:05+07:00</updated>
            <summary type="html">
                <![CDATA[
                    As we close the chapter on 2025, it is time to look back at a year filled with rigorous research, collaborative efforts, and meaningful contributions to the scientific community. This year-end seminar marks not just the passing of time, but the accumulation of knowledge and the expansion of our research&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                <p>As we close the chapter on 2025, it is time to look back at a year filled with rigorous research, collaborative efforts, and meaningful contributions to the scientific community. This year-end seminar marks not just the passing of time, but the accumulation of knowledge and the expansion of our research capabilities in <strong data-path-to-node="4" data-index-in-node="331">Artificial Intelligence, Computer Vision, and Educational Technology</strong>.</p>
<figure class="post__image"><img loading="lazy"  src="https://dunghvcs.github.io/media/posts/7/2025Khenthuong.jpg" alt="" width="2048" height="1365" sizes="(max-width: 1920px) 100vw, 1920px" srcset="https://dunghvcs.github.io/media/posts/7/responsive/2025Khenthuong-xs.jpg 640w ,https://dunghvcs.github.io/media/posts/7/responsive/2025Khenthuong-sm.jpg 768w ,https://dunghvcs.github.io/media/posts/7/responsive/2025Khenthuong-md.jpg 1024w ,https://dunghvcs.github.io/media/posts/7/responsive/2025Khenthuong-lg.jpg 1366w ,https://dunghvcs.github.io/media/posts/7/responsive/2025Khenthuong-xl.jpg 1600w ,https://dunghvcs.github.io/media/posts/7/responsive/2025Khenthuong-2xl.jpg 1920w"></figure>
<p data-path-to-node="6"><strong data-path-to-node="6" data-index-in-node="0">üìä Research Projects &amp; Grants</strong> This year, our lab continued to push the boundaries of applied AI. We successfully maintained momentum on key projects focusing on:</p>
<ul data-path-to-node="7">
<li>
<p data-path-to-node="7,0,0"><strong data-path-to-node="7,0,0" data-index-in-node="0">AI in Healthcare:</strong> Developing advanced diagnostic tools for medical imaging.</p>
</li>
<li>
<p data-path-to-node="7,1,0"><strong data-path-to-node="7,1,0" data-index-in-node="0">Intelligent Systems:</strong> Enhancing autonomous recognition capabilities for aerial and surveillance applications.</p>
</li>
<li>
<p data-path-to-node="7,2,0"><strong data-path-to-node="7,2,0" data-index-in-node="0">AI in Education:</strong> Applying deep learning to personalize and improve e-learning environments.</p>
</li>
</ul>
<p data-path-to-node="8"><i data-path-to-node="8" data-index-in-node="0">(Note: You can insert the exact number of funded projects here, e.g., "We successfully executed <strong data-path-to-node="8" data-index-in-node="96">3</strong> major research grants...")</i></p>
<p data-path-to-node="9"><strong data-path-to-node="9" data-index-in-node="0">üìù Key Publications (Journals &amp; Conferences)</strong> 2025 was a prolific year for dissemination. We are proud to have published impactful papers in reputable venues, addressing both theoretical improvements and practical applications of Deep Learning.</p>
<p data-path-to-node="9">ü§ù Community Service &amp; Leadership</p>
<p data-path-to-node="9">These achievements would not have been possible without the dedication of our research team, graduate students, and collaborators. As we move into <strong data-path-to-node="14" data-index-in-node="157">2026</strong>, we remain committed to solving real-world problems through innovation in Artificial Intelligence.</p>
<figure class="post__image"><img loading="lazy"  src="https://dunghvcs.github.io/media/posts/7/YearEndParty.jpg" alt="" width="2560" height="1440" sizes="(max-width: 1920px) 100vw, 1920px" srcset="https://dunghvcs.github.io/media/posts/7/responsive/YearEndParty-xs.jpg 640w ,https://dunghvcs.github.io/media/posts/7/responsive/YearEndParty-sm.jpg 768w ,https://dunghvcs.github.io/media/posts/7/responsive/YearEndParty-md.jpg 1024w ,https://dunghvcs.github.io/media/posts/7/responsive/YearEndParty-lg.jpg 1366w ,https://dunghvcs.github.io/media/posts/7/responsive/YearEndParty-xl.jpg 1600w ,https://dunghvcs.github.io/media/posts/7/responsive/YearEndParty-2xl.jpg 1920w"></figure>
            ]]>
        </content>
    </entry>
</feed>
