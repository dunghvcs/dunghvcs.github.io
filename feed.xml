<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <title>dunghv.github.io</title>
    <link href="https://dunghvcs.github.io/feed.xml" rel="self" />
    <link href="https://dunghvcs.github.io" />
    <updated>2026-02-13T11:56:48+07:00</updated>
    <author>
        <name>Van-Dung Hoang</name>
    </author>
    <id>https://dunghvcs.github.io</id>

    <entry>
        <title>Digital Image Processing</title>
        <author>
            <name>Van-Dung Hoang</name>
        </author>
        <link href="https://dunghvcs.github.io/digital-image-processing.html"/>
        <id>https://dunghvcs.github.io/digital-image-processing.html</id>
            <category term="Courses"/>

        <updated>2026-02-13T11:56:48+07:00</updated>
            <summary type="html">
                <![CDATA[
                    Digital Image Processing: Chapter 1: Introduction to image processing Chapter 2: Image enhancement in space domain Chapter 3: Image enhancement in frequency domain Chapter 4: Morphological image processing Chapter 5: Image segmentation Chapter 6: Feature extraction Chapter 7: Pattern recognition
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                <div class="CjVfdc">Digital Image Processing:<br>
<p>Chapter 1: Introduction to image processing</p>
<p>Chapter 2: Image enhancement in space domain</p>
<p>Chapter 3: Image enhancement in frequency domain</p>
<p>Chapter 4: Morphological image processing</p>
<p>Chapter 5: Image segmentation</p>
<p>Chapter 6: Feature extraction</p>
<p>Chapter 7: Pattern recognition</p>
</div>
<div><figure class="post__image"><img loading="lazy"  src="https://dunghvcs.github.io/media/posts/8/DIP1-2.png" alt="" width="813" height="594" sizes="(max-width: 1920px) 100vw, 1920px" srcset="https://dunghvcs.github.io/media/posts/8/responsive/DIP1-2-xs.png 640w ,https://dunghvcs.github.io/media/posts/8/responsive/DIP1-2-sm.png 768w ,https://dunghvcs.github.io/media/posts/8/responsive/DIP1-2-md.png 1024w ,https://dunghvcs.github.io/media/posts/8/responsive/DIP1-2-lg.png 1366w ,https://dunghvcs.github.io/media/posts/8/responsive/DIP1-2-xl.png 1600w ,https://dunghvcs.github.io/media/posts/8/responsive/DIP1-2-2xl.png 1920w"></figure></div>
<div>
<p>¬†</p>
</div>
<h3 id="h.i1ci6wnis21l_l" class="CDt4Ke zfr3Q OmQG5e" dir="ltr" tabindex="-1"></h3>
            ]]>
        </content>
    </entry>
    <entry>
        <title>Year end seminar¬†</title>
        <author>
            <name>Van-Dung Hoang</name>
        </author>
        <link href="https://dunghvcs.github.io/year-end-seminar.html"/>
        <id>https://dunghvcs.github.io/year-end-seminar.html</id>
            <category term="Seminar"/>

        <updated>2026-02-13T11:54:05+07:00</updated>
            <summary type="html">
                <![CDATA[
                    As we close the chapter on 2025, it is time to look back at a year filled with rigorous research, collaborative efforts, and meaningful contributions to the scientific community. This year-end seminar marks not just the passing of time, but the accumulation of knowledge and&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                <p>As we close the chapter on 2025, it is time to look back at a year filled with rigorous research, collaborative efforts, and meaningful contributions to the scientific community. This year-end seminar marks not just the passing of time, but the accumulation of knowledge and the expansion of our research capabilities in <strong data-path-to-node="4" data-index-in-node="331">Artificial Intelligence, Computer Vision, and Educational Technology</strong>.</p>
<figure class="post__image"><img loading="lazy"  src="https://dunghvcs.github.io/media/posts/7/2025Khenthuong.jpg" alt="" width="2048" height="1365" sizes="(max-width: 1920px) 100vw, 1920px" srcset="https://dunghvcs.github.io/media/posts/7/responsive/2025Khenthuong-xs.jpg 640w ,https://dunghvcs.github.io/media/posts/7/responsive/2025Khenthuong-sm.jpg 768w ,https://dunghvcs.github.io/media/posts/7/responsive/2025Khenthuong-md.jpg 1024w ,https://dunghvcs.github.io/media/posts/7/responsive/2025Khenthuong-lg.jpg 1366w ,https://dunghvcs.github.io/media/posts/7/responsive/2025Khenthuong-xl.jpg 1600w ,https://dunghvcs.github.io/media/posts/7/responsive/2025Khenthuong-2xl.jpg 1920w"></figure>
<p data-path-to-node="6"><strong data-path-to-node="6" data-index-in-node="0">üìä Research Projects &amp; Grants</strong> This year, our lab continued to push the boundaries of applied AI. We successfully maintained momentum on key projects focusing on:</p>
<ul data-path-to-node="7">
<li>
<p data-path-to-node="7,0,0"><strong data-path-to-node="7,0,0" data-index-in-node="0">AI in Healthcare:</strong> Developing advanced diagnostic tools for medical imaging.</p>
</li>
<li>
<p data-path-to-node="7,1,0"><strong data-path-to-node="7,1,0" data-index-in-node="0">Intelligent Systems:</strong> Enhancing autonomous recognition capabilities for aerial and surveillance applications.</p>
</li>
<li>
<p data-path-to-node="7,2,0"><strong data-path-to-node="7,2,0" data-index-in-node="0">AI in Education:</strong> Applying deep learning to personalize and improve e-learning environments.</p>
</li>
</ul>
<p data-path-to-node="8"><i data-path-to-node="8" data-index-in-node="0">(Note: You can insert the exact number of funded projects here, e.g., "We successfully executed <strong data-path-to-node="8" data-index-in-node="96">3</strong> major research grants...")</i></p>
<p data-path-to-node="9"><strong data-path-to-node="9" data-index-in-node="0">üìù Key Publications (Journals &amp; Conferences)</strong> 2025 was a prolific year for dissemination. We are proud to have published impactful papers in reputable venues, addressing both theoretical improvements and practical applications of Deep Learning.</p>
<p data-path-to-node="9">ü§ù Community Service &amp; Leadership</p>
<p data-path-to-node="9">These achievements would not have been possible without the dedication of our research team, graduate students, and collaborators. As we move into <strong data-path-to-node="14" data-index-in-node="157">2026</strong>, we remain committed to solving real-world problems through innovation in Artificial Intelligence.</p>
<figure class="post__image"><img loading="lazy"  src="https://dunghvcs.github.io/media/posts/7/YearEndParty.jpg" alt="" width="2560" height="1440" sizes="(max-width: 1920px) 100vw, 1920px" srcset="https://dunghvcs.github.io/media/posts/7/responsive/YearEndParty-xs.jpg 640w ,https://dunghvcs.github.io/media/posts/7/responsive/YearEndParty-sm.jpg 768w ,https://dunghvcs.github.io/media/posts/7/responsive/YearEndParty-md.jpg 1024w ,https://dunghvcs.github.io/media/posts/7/responsive/YearEndParty-lg.jpg 1366w ,https://dunghvcs.github.io/media/posts/7/responsive/YearEndParty-xl.jpg 1600w ,https://dunghvcs.github.io/media/posts/7/responsive/YearEndParty-2xl.jpg 1920w"></figure>
            ]]>
        </content>
    </entry>
    <entry>
        <title>[NAFOSTED] Project ambient understanding</title>
        <author>
            <name>Van-Dung Hoang</name>
        </author>
        <link href="https://dunghvcs.github.io/development-of-an-intelligent-system-for-ambient-understanding-applied-to-autonomous-navigation-in-outdoor-environment.html"/>
        <id>https://dunghvcs.github.io/development-of-an-intelligent-system-for-ambient-understanding-applied-to-autonomous-navigation-in-outdoor-environment.html</id>
            <category term="Research"/>

        <updated>2026-02-13T10:18:33+07:00</updated>
            <summary type="html">
                <![CDATA[
                    <h2><span style="color: #169179;"><strong><span style="color: #169179;">Development of an intelligent system for ambient understanding applied to autonomous navigation in outdoor environment.</span>¬†¬†</strong></span></h2>
<p>This project proposes and studies a novel method that improves efficiency of scene understanding, which is useful for autonomous navigation, based on the multiple sensors-based. The method is expected to provide the better scene understanding, which then allows a robot to avoid obstacles in front of its navigation. The method consists of some stages. First, a path planning is investigated, which concerns about the findings of the efficient path to facilitate the autonomous driving. The second is referred to the problem of the motion estimation and the localization prediction of running vehicle. It is addressed based on applying the fusion of cameras, LRF and GPS devices. Our research proposes a new method that uses the minimal set of parameters consisting of the geometrical constraints for estimating the 3D motion of vehicle using cameras and LRF. The cumulative errors of visual odometry are excluded using the GPS-based correction relied on the maximum likelihood estimation in particle filter. The semantic of object classification and detection are also studied. The obstacle detection, place recognition techniques are used as a solution to assisting the autonomous driver. We focus on dealing with detecting obstacles that commonly occur such as pedestrians and vehicles. The place recognition is also considered for scene understanding and mapping. We introduce improving of feature descriptors, deformable part model as well hybrid boosting SVM and neural network.¬†</p>

                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                <h2><span style="color: #169179;"><strong><span style="color: #169179;">Development of an intelligent system for ambient understanding applied to autonomous navigation in outdoor environment.</span>¬†¬†</strong></span></h2>
<p>This project proposes and studies a novel method that improves efficiency of scene understanding, which is useful for autonomous navigation, based on the multiple sensors-based. The method is expected to provide the better scene understanding, which then allows a robot to avoid obstacles in front of its navigation. The method consists of some stages. First, a path planning is investigated, which concerns about the findings of the efficient path to facilitate the autonomous driving. The second is referred to the problem of the motion estimation and the localization prediction of running vehicle. It is addressed based on applying the fusion of cameras, LRF and GPS devices. Our research proposes a new method that uses the minimal set of parameters consisting of the geometrical constraints for estimating the 3D motion of vehicle using cameras and LRF. The cumulative errors of visual odometry are excluded using the GPS-based correction relied on the maximum likelihood estimation in particle filter. The semantic of object classification and detection are also studied. The obstacle detection, place recognition techniques are used as a solution to assisting the autonomous driver. We focus on dealing with detecting obstacles that commonly occur such as pedestrians and vehicles. The place recognition is also considered for scene understanding and mapping. We introduce improving of feature descriptors, deformable part model as well hybrid boosting SVM and neural network.¬†</p>

<div class="gallery-wrapper"><div class="gallery" data-is-empty="false" data-translation="Add images" data-columns="3">
<figure class="gallery__item"><a href="https://dunghvcs.github.io/media/posts/5//gallery/NF1.png" data-size="956x916"><img loading="lazy" src="https://dunghvcs.github.io/media/posts/5//gallery/NF1-thumbnail.png" alt="" width="720" height="690"></a></figure>
<figure class="gallery__item"><a href="https://dunghvcs.github.io/media/posts/5//gallery/NF2.png" data-size="677x540"><img loading="lazy" src="https://dunghvcs.github.io/media/posts/5//gallery/NF2-thumbnail.png" alt="" width="677" height="540"></a></figure>
</div></div>
            ]]>
        </content>
    </entry>
    <entry>
        <title>ACIIDS2017, Kanazawa, Japan</title>
        <author>
            <name>Van-Dung Hoang</name>
        </author>
        <link href="https://dunghvcs.github.io/aciids2017-kanazawa-japan.html"/>
        <id>https://dunghvcs.github.io/aciids2017-kanazawa-japan.html</id>
            <category term="Conference Events"/>

        <updated>2026-02-13T09:29:56+07:00</updated>
            <summary type="html">
                <![CDATA[
                    ACIIDS is an international conference for researches in the filed of intelligent information and database systems. In this year, this conference was held during 3-5 April 2017 in Kaga, Japan. The aim of the conference is to provide an internationally respected forum for scientific research&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                <p class="zfr3Q CDt4Ke " dir="ltr"><span class="C9DxTc ">ACIIDS is an international conference for researches in the filed of intelligent information and database systems. In this year, this conference was held during 3-5 April 2017 in Kaga, Japan. The aim of the conference is to provide an internationally respected forum for scientific research in the technologies and applications of intelligent information and database systems.</span></p>
<p class="zfr3Q CDt4Ke " dir="ltr"><span class="C9DxTc ">Participant from ISLab is Dr. Van-Dung Hoang with a contribution "Boosting Discriminative Models for Activity Detection Using Local Feature Descriptors"</span></p>
<p class="zfr3Q CDt4Ke " dir="ltr"><span class="C9DxTc ">Over all, everything is well organized.</span></p>
<figure class="post__image"><img loading="lazy"  src="https://lh3.googleusercontent.com/sitesv/APaQ0SSZW6CB0pS_VufyLFH-WNUB1VaWnzvEA8Mqv-xQbBzOshNQ33B9KQ8ctnKyQpCGD63bcsNCcQSWjl2lhO5V9VFXowA7yKRjO2kX7VI1pXc4oysIGnu_K1E2zYPfOisPLtLw-DSPqUSng5ibj7SHVjJsPxh5V53kmC2FEKOomTBSh_qya77m5uzIB_QUZ692T1Vco0esaHW8PJIHN6FbUCVaqQaoxYOrL1-gDy4=w1280" alt="" data-is-external-image="true"></figure>
            ]]>
        </content>
    </entry>
    <entry>
        <title>ACIIDS2016, Danang, Vietnam</title>
        <author>
            <name>Van-Dung Hoang</name>
        </author>
        <link href="https://dunghvcs.github.io/aciids2016-danang-vietnam.html"/>
        <id>https://dunghvcs.github.io/aciids2016-danang-vietnam.html</id>
            <category term="Conference Events"/>

        <updated>2026-02-13T09:29:15+07:00</updated>
            <summary type="html">
                <![CDATA[
                    ACIIDS 2016 is an international scientific conference for research in the field of intelligent information and database systems, to be held during 14-16 March, 2016 in Da Nang, Vietnam. The aim of the conference is to provide an internationally respected forum for scientific research in&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                <p class="zfr3Q CDt4Ke " dir="ltr"><span class="C9DxTc ">ACIIDS 2016 is an international scientific conference for research in the field of intelligent information and database systems, to be held during 14-16 March, 2016 in Da Nang, Vietnam.</span></p>
<p class="zfr3Q CDt4Ke " dir="ltr"><span class="C9DxTc ">The aim of the conference is to provide an internationally respected forum for scientific research in the technologies and applications of intelligent information and database systems.</span></p>
<figure class="post__image"><img loading="lazy"  src="https://lh3.googleusercontent.com/sitesv/APaQ0SRTap8R7swosSpnHJqnm1G3aSM-Uh-eyybi2zkAnHXcHx-1vkDn-VVxLGiR-ZlSUIYpMLrcGU3Ia6ZX1aKS1WqUCMoEkOiHbnXjlf2nXvjfyeVhoe_AGqbslew2qtX51vRrOAlTpytlzqfmKfmVk9TtZu4Iw3b8e4hFSrj5iPqv8yDjHHFJ8x3WGz50PRDToXAGVeJ7yRld5IXNfdE-ltS3-YsTAsFp1YOi4lg=w1280" alt="" data-is-external-image="true"></figure>
<p class="zfr3Q CDt4Ke " dir="ltr"><span class="C9DxTc ">The conference is hosted by Vietnam-Korea Friendship Information Technology College (Viethanit), Vietnam and jointly organized by Wroc≈Çaw University of Technology, Poland in cooperation with IEEE SMC Technical Committee on Computational Collective Intelligence, Bina Nusantara University, Indonesia, Ton DucThang University, Vietnam, and QuangBinh University, Vietnam.</span></p>
<p class="zfr3Q CDt4Ke " dir="ltr"><span class="C9DxTc ">Participant from ISLab is Dr. Van-Dung Hoang with the contributions: "Accelerative Object Classification Using Cascade Structure for Vision Based Security Monitoring Systems" and "Multiscale Car Detection Using Oriented Gradient Feature and Boosting Machine"</span></p>
<figure class="post__image"><span class="C9DxTc ">Over all, everything is well organized.</span><img  src="https://lh3.googleusercontent.com/sitesv/APaQ0STP4i679gYNMFPvDrlLKjkXjMKPosGk1QRAkdK9hhj_9VS_1EXXrjiTU2s0z1x2ti7TwxMVIFbBdpsDszMnTFUaIkLuIB2VDrV14yFMufXC6nGNu52EfNiAS7f_JK_FEi7NoiAO-MqUNxtR6mZRkW2eMvt5y50TDtaf5BPiYkwLLFlUurHF4l9Aq7V3jAAFAoliIygtYCiToV3souQ0JJ5FsXK2oITWDUAQ=w1280" alt="" width="567" height="358" data-is-external-image="true"></figure><figure class="post__image"><img loading="lazy"  src="https://lh3.googleusercontent.com/sitesv/APaQ0SRTap8R7swosSpnHJqnm1G3aSM-Uh-eyybi2zkAnHXcHx-1vkDn-VVxLGiR-ZlSUIYpMLrcGU3Ia6ZX1aKS1WqUCMoEkOiHbnXjlf2nXvjfyeVhoe_AGqbslew2qtX51vRrOAlTpytlzqfmKfmVk9TtZu4Iw3b8e4hFSrj5iPqv8yDjHHFJ8x3WGz50PRDToXAGVeJ7yRld5IXNfdE-ltS3-YsTAsFp1YOi4lg=w1280" alt="" data-is-external-image="true"></figure>
            ]]>
        </content>
    </entry>
</feed>
